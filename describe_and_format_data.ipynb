{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ea00513",
   "metadata": {},
   "source": [
    "### Describe and Format Data for Modeling\n",
    "\n",
    "- Joel Stremmel\n",
    "- 04-19-23\n",
    "\n",
    "##### About\n",
    "\n",
    "Format the transcript data and survery responses to train binary classifiers with K-Fold cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac2c7a9",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd145b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import torch\n",
    "import pickle\n",
    "import statistics\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import pandas as pd\n",
    "from pdfminer.high_level import extract_text\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d89e2d",
   "metadata": {},
   "source": [
    "##### Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8dafa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set sequence lengths for distribution plot and sentiment model\n",
    "dist_max_seq_len = 32768\n",
    "\n",
    "# Set model/tokenizer paths\n",
    "dist_tokenizer_path = \"allenai/longformer-base-4096\"\n",
    "\n",
    "# Define data directory\n",
    "pdf_dir = './data/session_transcripts_iteration_2'\n",
    "\n",
    "# Define survey data path\n",
    "survey_path = './data/WDS_Session_Survey_April_13_2023_17.07_ONLY Iteration2.xlsx'\n",
    "\n",
    "# Define total number of sessions\n",
    "num_sessions = 10\n",
    "\n",
    "# Define the number of folds for K-Fold CV as a fraction  of the number of sessions\n",
    "# Set to -1 for the number of folds to be equal to the number of sessions\n",
    "# Otherwise, the number of folds is equal to the number of sessions divided by this value\n",
    "div_num_folds = 2\n",
    "\n",
    "# Group leaders\n",
    "leaders = [\n",
    "    'Hannah Norling (she/her)',\n",
    "    'Devin Kelly (she/her/hers)',\n",
    "    'Lisa Brownstone (She/Her)'\n",
    "]\n",
    "\n",
    "# Define session participants\n",
    "participants = {\n",
    "    'Betty_2': 8,\n",
    "    'Martha_2': 9,\n",
    "    'Tanya_2': 16,\n",
    "    'Bonnie_2': 14,\n",
    "    'Sharon_2': 10,\n",
    "    'Cecilia_2': 11,\n",
    "    'Maya_2': 17,\n",
    "    'Addison_2': 12,\n",
    "    'Penny_2': 15,\n",
    "    'Gemma_2': 13\n",
    "}\n",
    "\n",
    "# Define speakers as the combined set of leaders and participants\n",
    "speakers = leaders + list(participants.keys())\n",
    "\n",
    "# Set the default color cycle\n",
    "CB_color_cycle = ['#377eb8', '#ff7f00', '#4daf4a',\n",
    "                  '#f781bf', '#a65628', '#984ea3',\n",
    "                  '#999999', '#e41a1c', '#dede00',\n",
    "                  '#000000', '#8DA0CB', '#A6D854',\n",
    "                  '#E5C494']\n",
    "assert len(CB_color_cycle) == len(speakers), \"Number of colors should equal number of speakers.\"\n",
    "matplotlib.rcParams['axes.prop_cycle'] = matplotlib.cycler(color=CB_color_cycle) \n",
    "\n",
    "# Define separator token for utterances\n",
    "sep_token = \"</s>\"\n",
    "\n",
    "# Outcome variable\n",
    "outcome ='GSRS_Tot' # 'GEM'\n",
    "\n",
    "# Define outcome cutoff\n",
    "outcome_cutoff = 9 # 4\n",
    "\n",
    "# Optionally add a summary of each transcript to the text data\n",
    "add_summaries = False\n",
    "\n",
    "# If adding transcript summary, define input and output lengths\n",
    "max_transcript_seq_len = 4096\n",
    "max_summary_seq_len = 512\n",
    "\n",
    "# Define a seperator other than the sep token if adding summary\n",
    "# Instead of seperating utterances with the sep token, this approach\n",
    "# Uses the sep token to seperate the summary from the utterances and another\n",
    "# Token to seperate utterances\n",
    "utterance_seperator = \"\\n\\n\"\n",
    "\n",
    "# Define model to use for summarization and number of beams for text generation\n",
    "summarizer_path = \"google/flan-t5-large\"\n",
    "num_beams = 5\n",
    "\n",
    "# Define the prefix to prompt the summarizer\n",
    "# Adding more information about how the summary will be used to the prompt\n",
    "# Could improve performance beyond just asking for a generic summary\n",
    "summarize_prefix = \"Summarize: \""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82da9ae",
   "metadata": {},
   "source": [
    "##### Load Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88c647a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_tokenizer = AutoTokenizer.from_pretrained(dist_tokenizer_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f78b64c",
   "metadata": {},
   "source": [
    "##### Load Survey Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710a85d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(survey_path)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc49dc6",
   "metadata": {},
   "source": [
    "##### Define Score and Text Dataframes from Surveys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f934861b",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = df[[\n",
    "    'Session',\n",
    "    'ID',\n",
    "    outcome,\n",
    "]]\n",
    "score_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26eba526",
   "metadata": {},
   "source": [
    "##### View Outcome Distribution for Participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a7a89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(score_df[outcome], bins=6)\n",
    "plt.xlabel(outcome)\n",
    "plt.ylabel('Frequency')\n",
    "plt.title(f'{outcome} Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba1d72f",
   "metadata": {},
   "source": [
    "##### View Binarized Outcome Distribution for Participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204e711f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([1 if x >= outcome_cutoff else 0 for x in score_df[outcome].tolist()])\n",
    "plt.xlabel('Outcome')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Outcome Distribution')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Above cutoff: {score_df[score_df[outcome] < outcome_cutoff].shape[0]}.\")\n",
    "print(f\"Below cutoff: {score_df[score_df[outcome] >= outcome_cutoff].shape[0]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464372bc",
   "metadata": {},
   "source": [
    "##### Plot Scores per Participant per Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bb21e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for participant, participant_id in participants.items():\n",
    "    \n",
    "    x = score_df[score_df['ID'] == participant_id]['Session'].tolist()\n",
    "    y = score_df[score_df['ID'] == participant_id][outcome].tolist()\n",
    "    ax.plot(x, y, label=participant)\n",
    "\n",
    "    # Set plot title and axis labels\n",
    "    ax.set_title(f'{outcome} per Session per Participant')\n",
    "    ax.set_xlabel('Session Number')\n",
    "    ax.set_ylabel(f'{outcome}')\n",
    "\n",
    "    # Set legend\n",
    "    ax.legend(fontsize=6, loc='best')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2d84bc",
   "metadata": {},
   "source": [
    "##### Collect PDFs of Transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8bdce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_files = glob.glob(os.path.join(pdf_dir, '*.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8fefb7",
   "metadata": {},
   "source": [
    "##### Define Function to Remove Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccf6a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_remove(line):\n",
    "    line = line.strip()\n",
    "    if line.isdigit() or not line or (line.startswith('{') and line.endswith('}')):\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd625bf9",
   "metadata": {},
   "source": [
    "##### Extract Text and Count Words per Speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b8dce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save complete utterances\n",
    "speaker_utterances = {speaker: {num: [] for num in range(len(pdf_files))} for speaker in speakers}\n",
    "\n",
    "# Save session text\n",
    "session_texts = []\n",
    "\n",
    "# Iterate through files to extract words\n",
    "for i, file in enumerate(pdf_files):\n",
    "    \n",
    "    # Reset current speaker\n",
    "    current_speaker = None\n",
    "    \n",
    "    # Reset utterance\n",
    "    utterance = \"\"\n",
    "    \n",
    "    # Extract text\n",
    "    text = extract_text(file)\n",
    "    session_texts.append(text)\n",
    "    \n",
    "    # Iterate through text split on double new lines\n",
    "    for line in text.split('\\n'):\n",
    "        \n",
    "        # If the line is blank, keep going\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        # Check if one of the speakers is speaking\n",
    "        for speaker in speakers:\n",
    "            if line.startswith(speaker + ':'):\n",
    "                \n",
    "                # If the current speaker is the same as this speaker, keep going\n",
    "                if current_speaker == speaker:\n",
    "                    break\n",
    "                \n",
    "                # Otherwise, we have a new speaker and we want to save the full utterance\n",
    "                # from the previous speaker, set the new speaker, and reset the utterance\n",
    "                # If the current speaker is None, it's our first iteration and there's\n",
    "                # Nothing to save\n",
    "                else:\n",
    "                    if current_speaker is None:\n",
    "                        assert utterance == \"\", \"Expected utterance to be empty.\"\n",
    "                    else:\n",
    "                        speaker_utterances[current_speaker][i].append(utterance)\n",
    "                    current_speaker = speaker\n",
    "                    utterance = \"\"\n",
    "\n",
    "        # If we have a current speaker, add the utterance\n",
    "        if current_speaker:\n",
    "            \n",
    "            # Handle empty lines, bracketted info, and page numbers\n",
    "            if should_remove(line):\n",
    "                continue\n",
    "            \n",
    "            # Remove the speaker name from the line\n",
    "            # Split on any number of whitespaces to define the words in the line\n",
    "            clean_line = line.replace(current_speaker + ':', '')\n",
    "                \n",
    "            # Add to the utterance which will contain words seperated only by single spaces\n",
    "            utterance += \" \".join(clean_line.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d3ac6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_texts[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce64ac68",
   "metadata": {},
   "source": [
    "# To Do\n",
    "\n",
    "- Remove tabs in the middle of utterances and replace them with whitespace\n",
    "- Remove empty utterances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50de07b",
   "metadata": {},
   "source": [
    "##### Define Function to Differentiate between Participants and Leaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65da56e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_leader_tag(d, leaders):\n",
    "    \n",
    "    d_plot = {}\n",
    "    for k, v in d.items():\n",
    "        if k in leaders:\n",
    "            d_plot[k + ' - Leader'] = v\n",
    "        else:\n",
    "            d_plot[k] = v\n",
    "            \n",
    "    return d_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb33c13",
   "metadata": {},
   "source": [
    "##### Plot the Number of Utterances from Each Speaker for Each Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03677023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "for key in speaker_utterances:\n",
    "    x = list(speaker_utterances[key].keys())\n",
    "    y = [len(speaker_utterances[key][i]) for i in x]\n",
    "    \n",
    "    if key in leaders:\n",
    "        label = key + ' - Leader'\n",
    "    else:\n",
    "        label = key\n",
    "        \n",
    "    ax.plot(x, y, label=label)\n",
    "\n",
    "# Set plot title and axis labels\n",
    "ax.set_title('Number of Utterances per Session per Speaker')\n",
    "ax.set_xlabel('Session Number')\n",
    "ax.set_ylabel('Number of Utterances')\n",
    "\n",
    "# Set legend\n",
    "ax.legend(fontsize=6, loc='best')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e74d26c",
   "metadata": {},
   "source": [
    "##### Filter to Participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87749e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_utterances = {k: v for k, v in speaker_utterances.items() if k not in leaders}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af11eac8",
   "metadata": {},
   "source": [
    "##### Plot the Number of Tokens for all Utterances from Each Participant for Each Session and Save Utterance Text and Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69ac91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists to save utterance text, participant scores, and participant names and IDs\n",
    "X_fold_text = []\n",
    "y_fold_score = []\n",
    "participant_fold_names_ids = []\n",
    "\n",
    "# Generate plots and the data to fill the lists above by iterating through all participant utterances\n",
    "fig, ax = plt.subplots()\n",
    "for key in participant_utterances:\n",
    "    \n",
    "    # We'll use these for the plot\n",
    "    x = list(participant_utterances[key].keys())\n",
    "    y = []\n",
    "    \n",
    "    # Fill the empty lists above with info for this participant from each session \n",
    "    for i in x:\n",
    "        \n",
    "        # Build list of all utterances for this participant\n",
    "        all_utterances = participant_utterances[key][i]\n",
    "        \n",
    "        # Add the sep token to the utterance text to separate utterances and combine them into one string\n",
    "        all_utterance_text = sep_token.join(all_utterances)\n",
    "        \n",
    "        # Get the outcome score for the given session and participant\n",
    "        # Note that the session numbers start at 1 in score_df\n",
    "        s_num = i + 1\n",
    "        score_row = score_df[(score_df['Session'] == s_num) & (score_df['ID'] == participants[key])][outcome]\n",
    "        \n",
    "        # Check that either the score is missing and the row is empty or there is one value for the score\n",
    "        assert score_row.shape[0] in [0, 1], f\"Unexpected score row shape {score_row.shape}\"\n",
    "        \n",
    "        # If a non-missing score is recorded, save it along with the utterance text and participant name and ID\n",
    "        if score_row.shape[0] == 1 and not score_row.isnull().values.any():\n",
    "            \n",
    "            X_fold_text.append(all_utterance_text)\n",
    "            y_fold_score.append(score_row.item())\n",
    "            participant_fold_names_ids.append((i, key, participants[key]))\n",
    "        \n",
    "        # Compute the number of subwords in the utterance text \n",
    "        tokenized_text = dist_tokenizer(\n",
    "            all_utterance_text,\n",
    "            padding=False,\n",
    "            truncation=True,\n",
    "            max_length=dist_max_seq_len\n",
    "        )\n",
    "        num_subwords = len(tokenized_text['input_ids'])\n",
    "        y.append(num_subwords)\n",
    "    \n",
    "    if key in leaders:\n",
    "        label = key + ' - Leader'\n",
    "    else:\n",
    "        label = key\n",
    "        \n",
    "    ax.plot(x, y, label=label)\n",
    "\n",
    "# Set plot title and axis labels\n",
    "ax.set_title('All Utterances Length in Tokens per Session per Speaker')\n",
    "ax.set_xlabel('Session Number')\n",
    "ax.set_ylabel('All Utterances Length in Tokens')\n",
    "\n",
    "# Set legend\n",
    "ax.legend(fontsize=6, loc='best')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da1c7f5",
   "metadata": {},
   "source": [
    "##### Summarize Transcripts\n",
    "A prompt focused on the goal of providing the overall sentiment of the session might performance better than simply asking for a summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e305c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if add_summaries:\n",
    "    \n",
    "    # Load summarizer\n",
    "    summarizer_tokenizer = T5Tokenizer.from_pretrained(summarizer_path)\n",
    "    summarizer = T5ForConditionalGeneration.from_pretrained(summarizer_path)\n",
    "    \n",
    "    # Iterate over documents and summarize them\n",
    "    summaries = []\n",
    "    for sequence in session_texts:\n",
    "\n",
    "        # Tokenize input sequence with prefix\n",
    "        input_ids = summarizer_tokenizer.encode(\n",
    "            summarize_prefix + sequence,\n",
    "            return_tensors=\"pt\",\n",
    "            max_length=max_transcript_seq_len,\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        # Generate summary\n",
    "        summary_ids = summarizer.generate(\n",
    "            input_ids,\n",
    "            max_length=max_summary_seq_len,\n",
    "            num_beams=num_beams,\n",
    "            early_stopping=True\n",
    "        )\n",
    "\n",
    "        # Decode summary\n",
    "        summary = summarizer_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "        summaries.append(summary)\n",
    "        \n",
    "with open('results/summaries.txt', 'w') as f:\n",
    "    for line in summaries:\n",
    "        f.write(f\"{line}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d53bd5",
   "metadata": {},
   "source": [
    "##### Turn Saved Utterance Text and Scores into Data Folds and Threshold Scores\n",
    "- This assumes the data will be used to train binary classifiers with K-Fold cross-validation where K is equal to the number of sessions and the the binary outcome variable is defined according to `outcome_cutoff`.\n",
    "- If desired, the code block combines a summary of the entire transcript with all utterances for a given participant using the sep token to separate the summary for the utterances and a special utterance seperator to seperate utterances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c398b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_folds = {i: [] for i in range(num_sessions)}\n",
    "y_folds = {i: [] for i in range(num_sessions)}\n",
    "names_ids = {i: [] for i in range(num_sessions)}\n",
    "\n",
    "for record, text, score in zip(participant_fold_names_ids, X_fold_text, y_fold_score):\n",
    "    \n",
    "    session_number = record[0]\n",
    "    name = record[1]\n",
    "    participant_id = record[2]\n",
    "    \n",
    "    binary_score = 1 if score >= outcome_cutoff else 0\n",
    "    \n",
    "    if add_summaries:\n",
    "        summary = summaries[session_number]\n",
    "        sample_text = summary + sep_token + text.replace(sep_token, utterance_seperator)\n",
    "    else:\n",
    "        sample_text = text\n",
    "    \n",
    "    X_folds[session_number].append(sample_text)\n",
    "    y_folds[session_number].append(binary_score)\n",
    "    names_ids[session_number].append((name, participant_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2e0234",
   "metadata": {},
   "source": [
    "##### Optionally Combine Folds \n",
    "If desired, K can be less than the number of sessions. Use `div_num_folds` to reduce the number of folds to `num_sessions` / `div_num_folds`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc49978",
   "metadata": {},
   "outputs": [],
   "source": [
    "if div_num_folds > 0:\n",
    "    X_folds = {fold: X_folds[i] + X_folds[i + 1] for fold, i in enumerate(range(0, num_sessions, div_num_folds))}\n",
    "    y_folds = {fold: y_folds[i] + y_folds[i + 1] for fold, i in enumerate(range(0, num_sessions, div_num_folds))}\n",
    "    names_ids = {fold: names_ids[i] + names_ids[i + 1] for fold, i in enumerate(range(0, num_sessions, div_num_folds))}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6a4827",
   "metadata": {},
   "source": [
    "##### Pickle the Data to Use for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e681ed93",
   "metadata": {},
   "outputs": [],
   "source": [
    "if add_summaries:\n",
    "    \n",
    "    with open('data/Xwsum_folds.pkl', 'wb') as f:\n",
    "        pickle.dump(X_folds, f)\n",
    "else:\n",
    "    \n",
    "    with open('data/X_folds.pkl', 'wb') as f:\n",
    "        pickle.dump(X_folds, f)\n",
    "\n",
    "with open('data/y_folds.pkl', 'wb') as f:\n",
    "    pickle.dump(y_folds, f)\n",
    "    \n",
    "with open('data/names_ids.pkl', 'wb') as f:\n",
    "    pickle.dump(names_ids, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b1ebc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transcripts",
   "language": "python",
   "name": "transcripts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
