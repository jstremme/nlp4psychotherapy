{"cells":[{"cell_type":"markdown","id":"6ea00513","metadata":{"id":"6ea00513"},"source":["### Fine-Tune Big Bird Large\n","\n","- Joel Stremmel\n","- 04-12-23\n","\n","##### About\n","\n","Fine-Tune Big Bird Large on the formatted data using K-Fold Cross-Validation and save the scores."]},{"cell_type":"markdown","source":["##### Install Libraries"],"metadata":{"id":"2p3XLv9_FSz3"},"id":"2p3XLv9_FSz3"},{"cell_type":"code","source":["!pip install -q pdfminer.six\n","!pip install -q pandas\n","!pip install -q transformers\n","!pip install -q openpyxl\n","!pip install -q datasets"],"metadata":{"id":"GwH1cZ40FSSP","colab":{"base_uri":"https://localhost:8080/"},"outputId":"490bcbac-565c-4bc3-b015-46bc77ab1b51"},"id":"GwH1cZ40FSSP","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m101.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"markdown","id":"9ac2c7a9","metadata":{"id":"9ac2c7a9"},"source":["##### Imports"]},{"cell_type":"code","execution_count":null,"id":"dd145b3a","metadata":{"id":"dd145b3a"},"outputs":[],"source":["import os\n","import re\n","import glob\n","import pickle\n","import torch\n","import numpy as np\n","import pandas as pd\n","from datasets import Dataset\n","from transformers import (\n","    AutoTokenizer,\n","    AutoModelForSequenceClassification,\n","    Trainer,\n","    TrainingArguments\n",")"]},{"cell_type":"markdown","id":"19d89e2d","metadata":{"id":"19d89e2d"},"source":["##### Set Parameters"]},{"cell_type":"code","execution_count":null,"id":"ccfa5892","metadata":{"id":"ccfa5892"},"outputs":[],"source":["max_seq_len = 4096\n","batch_size = 2\n","accumulation_steps = 16\n","lr = 0.00005\n","weight_decay = 0.01\n","adam_beta1 = 0.9\n","adam_beta2 = 0.999\n","adam_epsilon = 0.00000001\n","warmup_steps = 10\n","logging_steps = 1\n","num_workers = 2\n","seed = 44\n","epochs = 100\n","fp16 = True\n","colab = True\n","require_high_ram = False\n","input_dir = \"/content/drive/MyDrive/data/\"\n","model_output_dir = \"model_output\"\n","results_dir = \"/content/drive/MyDrive/results/\"\n","model_key = \"bbl\"\n","lm_path = \"google/bigbird-roberta-large\""]},{"cell_type":"markdown","id":"fccb2634","metadata":{"id":"fccb2634"},"source":["##### Disable Tokenizer Parallelism\n","This is mostly to avoid warnings."]},{"cell_type":"code","execution_count":null,"id":"e13a3d5f","metadata":{"id":"e13a3d5f"},"outputs":[],"source":["os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""]},{"cell_type":"markdown","source":["##### Check Runtime"],"metadata":{"id":"ml0hfOeeeb7U"},"id":"ml0hfOeeeb7U"},{"cell_type":"code","source":["if colab:\n","  \n","    gpu_info = !nvidia-smi\n","    gpu_info = '\\n'.join(gpu_info)\n","    if gpu_info.find('failed') >= 0:\n","      print('Not connected to a GPU')\n","    else:\n","      print(gpu_info)\n","\n","if require_high_ram:\n","\n","    from psutil import virtual_memory\n","    ram_gb = virtual_memory().total / 1e9\n","    print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","    if ram_gb < 20:\n","      print('Not using a high-RAM runtime')\n","    else:\n","      print('You are using a high-RAM runtime!')"],"metadata":{"id":"3K1GJkO8ecs9"},"id":"3K1GJkO8ecs9","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"2f78b64c","metadata":{"id":"2f78b64c"},"source":["##### Load Formatted Data"]},{"cell_type":"code","execution_count":null,"id":"710a85d0","metadata":{"id":"710a85d0"},"outputs":[],"source":["with open(os.path.join(input_dir, 'X_folds.pkl'), 'rb') as f:\n","    X_folds = pickle.load(f)\n","\n","with open(os.path.join(input_dir, 'y_folds.pkl'), 'rb') as f:\n","    y_folds = pickle.load(f)"]},{"cell_type":"markdown","id":"5d6b559a","metadata":{"id":"5d6b559a"},"source":["##### Check Data Shape"]},{"cell_type":"code","execution_count":null,"id":"bb7c83b6","metadata":{"id":"bb7c83b6"},"outputs":[],"source":["assert len(X_folds) == len(y_folds), \"Expected the same number of folds in X and y.\"\n","X = list(X_folds.values())\n","y = list(y_folds.values())"]},{"cell_type":"markdown","id":"aac7cd9d","metadata":{"id":"aac7cd9d"},"source":["##### Check Target Prevalence"]},{"cell_type":"code","execution_count":null,"id":"2164340a","metadata":{"id":"2164340a","outputId":"c0650a0c-2508-40f7-8a61-674175f0c4c5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Target prevalance: 0.5.\n"]}],"source":["print(f\"Target prevalance: {np.mean(np.concatenate(y))}.\")"]},{"cell_type":"markdown","id":"15ff6576","metadata":{"id":"15ff6576"},"source":["##### Check that GPU is Available"]},{"cell_type":"code","execution_count":null,"id":"617bd083","metadata":{"id":"617bd083","outputId":"d689999b-36f5-4503-ef08-1fa40a7151ea"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/joel_stremmel/anaconda3/envs/transcripts/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n","  return torch._C._cuda_getDeviceCount() > 0\n"]},{"ename":"AssertionError","evalue":"Run this script on a GPU.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun this script on a GPU.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39m__version__)\n","\u001b[0;31mAssertionError\u001b[0m: Run this script on a GPU."]}],"source":["assert torch.cuda.is_available(), \"Run this script on a GPU.\"\n","print(torch.__version__)"]},{"cell_type":"markdown","id":"85f2951e","metadata":{"id":"85f2951e"},"source":["##### Tokenize Text and Fit Model to Each Fold"]},{"cell_type":"code","execution_count":null,"id":"45cc6d29","metadata":{"id":"45cc6d29"},"outputs":[],"source":["y_probs, y_trues = [], []\n","for i in range(len(X)):\n","    \n","    print(f\"Fitting model using fold {i} as out of fold data.\")\n","    \n","    # Identify train folds and shuffle samples\n","    X_train, y_train = np.concatenate(X[0:i] + X[i+1:], axis=0), np.concatenate(y[0:i] + y[i+1:], axis=0)\n","    indices = np.arange(len(y_train))\n","    np.random.shuffle(indices)\n","    X_train, y_train = X_train[indices], y_train[indices]\n","    \n","    # Identify test folds\n","    X_test, y_test = X[i], y[i]\n","    \n","    # Format text and label data as HuggingFace dataset\n","    train_dataset = Dataset.from_dict({\"text\": X_train, \"label\": y_train})\n","    test_dataset = Dataset.from_dict({\"text\": X_test, \"label\": y_test})\n","    \n","    # Load model and tokenizer\n","    # This will reset the model weights with each new iteration\n","    tokenizer = AutoTokenizer.from_pretrained(lm_path)\n","    model = AutoModelForSequenceClassification.from_pretrained(\n","        lm_path,\n","        num_labels=2,\n","        return_dict=True,\n","        problem_type=\"single_label_classification\"\n","    )\n","    \n","    # Define function to tokenize text\n","    def tokenize_function(batch):\n","        \n","        return tokenizer(\n","            batch[\"text\"],\n","            padding=\"max_length\",\n","            truncation=True,\n","            max_length=max_seq_len\n","        )\n","    \n","    # Tokenize train dataset\n","    train_dataset = train_dataset.map(\n","        tokenize_function,\n","        batched=True,\n","        remove_columns=[\"text\"],\n","        batch_size=batch_size\n","    )\n","    train_dataset.set_format(\"pt\")\n","    \n","    # Tokenize test dataset\n","    test_dataset = test_dataset.map(\n","        tokenize_function,\n","        batched=True,\n","        remove_columns=[\"text\"],\n","        batch_size=batch_size\n","    )\n","    test_dataset.set_format(\"pt\")\n","    \n","    # Define training arguments\n","    training_args= TrainingArguments(\n","        output_dir=model_output_dir,\n","        num_train_epochs=epochs,\n","        per_device_train_batch_size=batch_size,\n","        gradient_accumulation_steps=accumulation_steps,\n","        warmup_steps=warmup_steps,\n","        logging_steps=logging_steps,\n","        weight_decay=weight_decay,\n","        learning_rate=lr,\n","        seed=seed,\n","        adam_beta1=adam_beta1,\n","        adam_beta2=adam_beta2,\n","        adam_epsilon=adam_epsilon,\n","        dataloader_num_workers=num_workers,\n","        fp16=fp16,\n","        run_name=model_key,\n","        logging_strategy=\"steps\",\n","        save_strategy=\"no\",\n","        lr_scheduler_type='linear',\n","        optim=\"adamw_torch\",\n","        do_eval=False,\n","        fp16_full_eval=False,\n","        sharded_ddp=False,\n","        gradient_checkpointing=True,\n","        load_best_model_at_end=True,\n","        prediction_loss_only=False,\n","        disable_tqdm=True,\n","        logging_dir=None,\n","    )\n","    \n","    # Define model training\n","    trainer = Trainer(\n","        model=model,\n","        args=training_args,\n","        train_dataset=train_dataset\n","    )\n","    \n","    # Train model\n","    trainer.train()\n","    \n","    # Predict on test dataset\n","    output = trainer.predict(test_dataset)\n","    labels = output.label_ids\n","    y_prob = torch.sigmoid(torch.tensor(output.predictions).double()).numpy()[:, 1]\n","\n","    # Save scores and labels\n","    y_probs.append(y_prob)\n","    y_trues.append(labels)"]},{"cell_type":"markdown","id":"7da93cef","metadata":{"id":"7da93cef"},"source":["##### Save Model Probabilities on Test Folds and True Labels"]},{"cell_type":"code","execution_count":null,"id":"6bbff8d9","metadata":{"id":"6bbff8d9"},"outputs":[],"source":["with open(os.path.join(results_dir, f'{model_key}_y_trues.pkl'), 'wb') as f:\n","    pickle.dump(y_trues, f)\n","\n","with open(os.path.join(results_dir, f'{model_key}_y_probs.pkl'), 'wb') as f:\n","    pickle.dump(y_probs, f)"]},{"cell_type":"code","execution_count":null,"id":"6e4d8469","metadata":{"id":"6e4d8469"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"transcripts","language":"python","name":"transcripts"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"},"colab":{"provenance":[{"file_id":"17WWrz0X7lOh9JmFqsQz8P4c2H4ro1xZm","timestamp":1681313719619}],"gpuType":"T4"},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":5}