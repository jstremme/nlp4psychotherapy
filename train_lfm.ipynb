{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ea00513",
   "metadata": {},
   "source": [
    "### Fine-Tune Longformer Mini\n",
    "\n",
    "- Joel Stremmel\n",
    "- 04-11-23\n",
    "\n",
    "##### About\n",
    "\n",
    "Fine-Tune Longformer Mini on the formatted data using K-Fold Cross-Validation and save the scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac2c7a9",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd145b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d89e2d",
   "metadata": {},
   "source": [
    "##### Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccfa5892",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 1024\n",
    "batch_size = 32\n",
    "accumulation_steps = 1\n",
    "lr = 0.00005\n",
    "weight_decay = 0.01\n",
    "adam_beta1 = 0.9\n",
    "adam_beta2 = 0.999\n",
    "adam_epsilon = 0.00000001\n",
    "warmup_steps = 10\n",
    "logging_steps = 1\n",
    "num_workers = 8\n",
    "seed = 44\n",
    "epochs = 100\n",
    "fp16 = True\n",
    "output_dir = \"lf_output\"\n",
    "lm_path = \"kiddothe2b/longformer-mini-1024\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccb2634",
   "metadata": {},
   "source": [
    "##### Disable Tokenizer Parallelism\n",
    "This is mostly to avoid warnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e13a3d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f78b64c",
   "metadata": {},
   "source": [
    "##### Load Formatted Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "710a85d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/X_folds.pkl', 'rb') as f:\n",
    "    X_folds = pickle.load(f)\n",
    "\n",
    "with open('data/y_folds.pkl', 'rb') as f:\n",
    "    y_folds = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6b559a",
   "metadata": {},
   "source": [
    "##### Check Data Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb7c83b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(X_folds) == len(y_folds), \"Expected the same number of folds in X and y.\"\n",
    "X = list(X_folds.values())\n",
    "y = list(y_folds.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac7cd9d",
   "metadata": {},
   "source": [
    "##### Check Target Prevalence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2164340a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target prevalance: 0.5.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Target prevalance: {np.mean(np.concatenate(y))}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ff6576",
   "metadata": {},
   "source": [
    "##### Check that GPU is Available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "617bd083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.1+cu101\n"
     ]
    }
   ],
   "source": [
    "assert torch.cuda.is_available(), \"Run this script on a GPU.\"\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f2951e",
   "metadata": {},
   "source": [
    "##### Tokenize Text and Fit Model to Each Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45cc6d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model using fold 0 as out of fold data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at kiddothe2b/longformer-mini-1024 were not used when initializing LongformerForSequenceClassification: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.bias', 'longformer.embeddings.position_ids']\n",
      "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at kiddothe2b/longformer-mini-1024 and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/54 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/18 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.698, 'learning_rate': 5e-06, 'epoch': 0.5}\n",
      "{'loss': 0.7025, 'learning_rate': 1e-05, 'epoch': 1.0}\n",
      "{'loss': 0.6969, 'learning_rate': 1.5e-05, 'epoch': 1.5}\n",
      "{'loss': 0.6966, 'learning_rate': 2e-05, 'epoch': 2.0}\n",
      "{'loss': 0.678, 'learning_rate': 2.5e-05, 'epoch': 2.5}\n",
      "{'loss': 0.6969, 'learning_rate': 3e-05, 'epoch': 3.0}\n",
      "{'loss': 0.6701, 'learning_rate': 3.5e-05, 'epoch': 3.5}\n",
      "{'loss': 0.6919, 'learning_rate': 4e-05, 'epoch': 4.0}\n",
      "{'loss': 0.6643, 'learning_rate': 4.5e-05, 'epoch': 4.5}\n",
      "{'loss': 0.6983, 'learning_rate': 5e-05, 'epoch': 5.0}\n",
      "{'loss': 0.6894, 'learning_rate': 4.973684210526316e-05, 'epoch': 5.5}\n",
      "{'loss': 0.6354, 'learning_rate': 4.9473684210526315e-05, 'epoch': 6.0}\n",
      "{'loss': 0.6571, 'learning_rate': 4.921052631578947e-05, 'epoch': 6.5}\n",
      "{'loss': 0.6423, 'learning_rate': 4.8947368421052635e-05, 'epoch': 7.0}\n",
      "{'loss': 0.6159, 'learning_rate': 4.868421052631579e-05, 'epoch': 7.5}\n",
      "{'loss': 0.6729, 'learning_rate': 4.842105263157895e-05, 'epoch': 8.0}\n",
      "{'loss': 0.6183, 'learning_rate': 4.8157894736842105e-05, 'epoch': 8.5}\n",
      "{'loss': 0.6238, 'learning_rate': 4.789473684210526e-05, 'epoch': 9.0}\n",
      "{'loss': 0.6119, 'learning_rate': 4.7631578947368424e-05, 'epoch': 9.5}\n",
      "{'loss': 0.5942, 'learning_rate': 4.736842105263158e-05, 'epoch': 10.0}\n",
      "{'loss': 0.5771, 'learning_rate': 4.7105263157894744e-05, 'epoch': 10.5}\n",
      "{'loss': 0.5769, 'learning_rate': 4.68421052631579e-05, 'epoch': 11.0}\n",
      "{'loss': 0.5725, 'learning_rate': 4.657894736842106e-05, 'epoch': 11.5}\n",
      "{'loss': 0.532, 'learning_rate': 4.6315789473684214e-05, 'epoch': 12.0}\n",
      "{'loss': 0.5268, 'learning_rate': 4.605263157894737e-05, 'epoch': 12.5}\n",
      "{'loss': 0.4961, 'learning_rate': 4.5789473684210527e-05, 'epoch': 13.0}\n",
      "{'loss': 0.4917, 'learning_rate': 4.552631578947369e-05, 'epoch': 13.5}\n",
      "{'loss': 0.46, 'learning_rate': 4.5263157894736846e-05, 'epoch': 14.0}\n",
      "{'loss': 0.4977, 'learning_rate': 4.5e-05, 'epoch': 14.5}\n",
      "{'loss': 0.4345, 'learning_rate': 4.473684210526316e-05, 'epoch': 15.0}\n",
      "{'loss': 0.414, 'learning_rate': 4.4473684210526316e-05, 'epoch': 15.5}\n",
      "{'loss': 0.439, 'learning_rate': 4.421052631578947e-05, 'epoch': 16.0}\n",
      "{'loss': 0.4305, 'learning_rate': 4.394736842105263e-05, 'epoch': 16.5}\n",
      "{'loss': 0.3739, 'learning_rate': 4.368421052631579e-05, 'epoch': 17.0}\n",
      "{'loss': 0.4011, 'learning_rate': 4.342105263157895e-05, 'epoch': 17.5}\n",
      "{'loss': 0.332, 'learning_rate': 4.3157894736842105e-05, 'epoch': 18.0}\n",
      "{'loss': 0.3614, 'learning_rate': 4.289473684210527e-05, 'epoch': 18.5}\n",
      "{'loss': 0.3156, 'learning_rate': 4.2631578947368425e-05, 'epoch': 19.0}\n",
      "{'loss': 0.3149, 'learning_rate': 4.236842105263158e-05, 'epoch': 19.5}\n",
      "{'loss': 0.349, 'learning_rate': 4.210526315789474e-05, 'epoch': 20.0}\n",
      "{'loss': 0.2986, 'learning_rate': 4.18421052631579e-05, 'epoch': 20.5}\n",
      "{'loss': 0.3027, 'learning_rate': 4.157894736842106e-05, 'epoch': 21.0}\n",
      "{'loss': 0.2927, 'learning_rate': 4.1315789473684214e-05, 'epoch': 21.5}\n",
      "{'loss': 0.2952, 'learning_rate': 4.105263157894737e-05, 'epoch': 22.0}\n",
      "{'loss': 0.2643, 'learning_rate': 4.078947368421053e-05, 'epoch': 22.5}\n",
      "{'loss': 0.2517, 'learning_rate': 4.0526315789473684e-05, 'epoch': 23.0}\n",
      "{'loss': 0.2416, 'learning_rate': 4.026315789473684e-05, 'epoch': 23.5}\n",
      "{'loss': 0.2773, 'learning_rate': 4e-05, 'epoch': 24.0}\n",
      "{'loss': 0.2354, 'learning_rate': 3.973684210526316e-05, 'epoch': 24.5}\n",
      "{'loss': 0.2361, 'learning_rate': 3.9473684210526316e-05, 'epoch': 25.0}\n",
      "{'loss': 0.2385, 'learning_rate': 3.921052631578947e-05, 'epoch': 25.5}\n",
      "{'loss': 0.2287, 'learning_rate': 3.894736842105263e-05, 'epoch': 26.0}\n",
      "{'loss': 0.1825, 'learning_rate': 3.868421052631579e-05, 'epoch': 26.5}\n",
      "{'loss': 0.2402, 'learning_rate': 3.842105263157895e-05, 'epoch': 27.0}\n",
      "{'loss': 0.1493, 'learning_rate': 3.815789473684211e-05, 'epoch': 27.5}\n",
      "{'loss': 0.2722, 'learning_rate': 3.789473684210527e-05, 'epoch': 28.0}\n",
      "{'loss': 0.2062, 'learning_rate': 3.7631578947368425e-05, 'epoch': 28.5}\n",
      "{'loss': 0.1845, 'learning_rate': 3.736842105263158e-05, 'epoch': 29.0}\n",
      "{'loss': 0.1531, 'learning_rate': 3.710526315789474e-05, 'epoch': 29.5}\n",
      "{'loss': 0.2652, 'learning_rate': 3.6842105263157895e-05, 'epoch': 30.0}\n",
      "{'loss': 0.1811, 'learning_rate': 3.657894736842106e-05, 'epoch': 30.5}\n",
      "{'loss': 0.1907, 'learning_rate': 3.6315789473684214e-05, 'epoch': 31.0}\n",
      "{'loss': 0.1629, 'learning_rate': 3.605263157894737e-05, 'epoch': 31.5}\n",
      "{'loss': 0.321, 'learning_rate': 3.578947368421053e-05, 'epoch': 32.0}\n",
      "{'loss': 0.1833, 'learning_rate': 3.5526315789473684e-05, 'epoch': 32.5}\n",
      "{'loss': 0.123, 'learning_rate': 3.526315789473684e-05, 'epoch': 33.0}\n",
      "{'loss': 0.1128, 'learning_rate': 3.5e-05, 'epoch': 33.5}\n",
      "{'loss': 0.2354, 'learning_rate': 3.473684210526316e-05, 'epoch': 34.0}\n",
      "{'loss': 0.1657, 'learning_rate': 3.447368421052632e-05, 'epoch': 34.5}\n",
      "{'loss': 0.1616, 'learning_rate': 3.421052631578947e-05, 'epoch': 35.0}\n",
      "{'loss': 0.1211, 'learning_rate': 3.3947368421052636e-05, 'epoch': 35.5}\n",
      "{'loss': 0.2149, 'learning_rate': 3.368421052631579e-05, 'epoch': 36.0}\n",
      "{'loss': 0.1407, 'learning_rate': 3.342105263157895e-05, 'epoch': 36.5}\n",
      "{'loss': 0.1717, 'learning_rate': 3.3157894736842106e-05, 'epoch': 37.0}\n",
      "{'loss': 0.1779, 'learning_rate': 3.289473684210527e-05, 'epoch': 37.5}\n",
      "{'loss': 0.0952, 'learning_rate': 3.2631578947368426e-05, 'epoch': 38.0}\n",
      "{'loss': 0.1594, 'learning_rate': 3.236842105263158e-05, 'epoch': 38.5}\n",
      "{'loss': 0.132, 'learning_rate': 3.210526315789474e-05, 'epoch': 39.0}\n",
      "{'loss': 0.1159, 'learning_rate': 3.1842105263157895e-05, 'epoch': 39.5}\n",
      "{'loss': 0.1755, 'learning_rate': 3.157894736842105e-05, 'epoch': 40.0}\n",
      "{'loss': 0.1667, 'learning_rate': 3.131578947368421e-05, 'epoch': 40.5}\n",
      "{'loss': 0.1277, 'learning_rate': 3.105263157894737e-05, 'epoch': 41.0}\n",
      "{'loss': 0.1507, 'learning_rate': 3.078947368421053e-05, 'epoch': 41.5}\n",
      "{'loss': 0.108, 'learning_rate': 3.0526315789473684e-05, 'epoch': 42.0}\n",
      "{'loss': 0.1576, 'learning_rate': 3.0263157894736844e-05, 'epoch': 42.5}\n",
      "{'loss': 0.0967, 'learning_rate': 3e-05, 'epoch': 43.0}\n",
      "{'loss': 0.0903, 'learning_rate': 2.9736842105263157e-05, 'epoch': 43.5}\n",
      "{'loss': 0.2416, 'learning_rate': 2.9473684210526314e-05, 'epoch': 44.0}\n",
      "{'loss': 0.1172, 'learning_rate': 2.9210526315789477e-05, 'epoch': 44.5}\n",
      "{'loss': 0.1707, 'learning_rate': 2.8947368421052634e-05, 'epoch': 45.0}\n",
      "{'loss': 0.1617, 'learning_rate': 2.868421052631579e-05, 'epoch': 45.5}\n",
      "{'loss': 0.0592, 'learning_rate': 2.842105263157895e-05, 'epoch': 46.0}\n",
      "{'loss': 0.1169, 'learning_rate': 2.8157894736842106e-05, 'epoch': 46.5}\n",
      "{'loss': 0.1351, 'learning_rate': 2.7894736842105263e-05, 'epoch': 47.0}\n",
      "{'loss': 0.1424, 'learning_rate': 2.7631578947368426e-05, 'epoch': 47.5}\n",
      "{'loss': 0.1131, 'learning_rate': 2.7368421052631583e-05, 'epoch': 48.0}\n",
      "{'loss': 0.1037, 'learning_rate': 2.710526315789474e-05, 'epoch': 48.5}\n",
      "{'loss': 0.2053, 'learning_rate': 2.6842105263157896e-05, 'epoch': 49.0}\n",
      "{'loss': 0.1613, 'learning_rate': 2.6578947368421052e-05, 'epoch': 49.5}\n",
      "{'loss': 0.1014, 'learning_rate': 2.6315789473684212e-05, 'epoch': 50.0}\n",
      "{'loss': 0.2, 'learning_rate': 2.605263157894737e-05, 'epoch': 50.5}\n",
      "{'loss': 0.0483, 'learning_rate': 2.578947368421053e-05, 'epoch': 51.0}\n",
      "{'loss': 0.1585, 'learning_rate': 2.5526315789473688e-05, 'epoch': 51.5}\n",
      "{'loss': 0.1112, 'learning_rate': 2.5263157894736845e-05, 'epoch': 52.0}\n",
      "{'loss': 0.1265, 'learning_rate': 2.5e-05, 'epoch': 52.5}\n",
      "{'loss': 0.1282, 'learning_rate': 2.4736842105263158e-05, 'epoch': 53.0}\n",
      "{'loss': 0.1465, 'learning_rate': 2.4473684210526318e-05, 'epoch': 53.5}\n",
      "{'loss': 0.0836, 'learning_rate': 2.4210526315789474e-05, 'epoch': 54.0}\n",
      "{'loss': 0.0763, 'learning_rate': 2.394736842105263e-05, 'epoch': 54.5}\n",
      "{'loss': 0.1781, 'learning_rate': 2.368421052631579e-05, 'epoch': 55.0}\n",
      "{'loss': 0.1632, 'learning_rate': 2.342105263157895e-05, 'epoch': 55.5}\n",
      "{'loss': 0.0666, 'learning_rate': 2.3157894736842107e-05, 'epoch': 56.0}\n",
      "{'loss': 0.125, 'learning_rate': 2.2894736842105263e-05, 'epoch': 56.5}\n",
      "{'loss': 0.1278, 'learning_rate': 2.2631578947368423e-05, 'epoch': 57.0}\n",
      "{'loss': 0.1546, 'learning_rate': 2.236842105263158e-05, 'epoch': 57.5}\n",
      "{'loss': 0.1285, 'learning_rate': 2.2105263157894736e-05, 'epoch': 58.0}\n",
      "{'loss': 0.0834, 'learning_rate': 2.1842105263157896e-05, 'epoch': 58.5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1564, 'learning_rate': 2.1578947368421053e-05, 'epoch': 59.0}\n",
      "{'loss': 0.1117, 'learning_rate': 2.1315789473684212e-05, 'epoch': 59.5}\n",
      "{'loss': 0.1275, 'learning_rate': 2.105263157894737e-05, 'epoch': 60.0}\n",
      "{'loss': 0.0562, 'learning_rate': 2.078947368421053e-05, 'epoch': 60.5}\n",
      "{'loss': 0.2231, 'learning_rate': 2.0526315789473685e-05, 'epoch': 61.0}\n",
      "{'loss': 0.1572, 'learning_rate': 2.0263157894736842e-05, 'epoch': 61.5}\n",
      "{'loss': 0.0589, 'learning_rate': 2e-05, 'epoch': 62.0}\n",
      "{'loss': 0.0674, 'learning_rate': 1.9736842105263158e-05, 'epoch': 62.5}\n",
      "{'loss': 0.1764, 'learning_rate': 1.9473684210526315e-05, 'epoch': 63.0}\n",
      "{'loss': 0.0956, 'learning_rate': 1.9210526315789474e-05, 'epoch': 63.5}\n",
      "{'loss': 0.158, 'learning_rate': 1.8947368421052634e-05, 'epoch': 64.0}\n",
      "{'loss': 0.1399, 'learning_rate': 1.868421052631579e-05, 'epoch': 64.5}\n",
      "{'loss': 0.0833, 'learning_rate': 1.8421052631578947e-05, 'epoch': 65.0}\n",
      "{'loss': 0.1378, 'learning_rate': 1.8157894736842107e-05, 'epoch': 65.5}\n",
      "{'loss': 0.1011, 'learning_rate': 1.7894736842105264e-05, 'epoch': 66.0}\n",
      "{'loss': 0.1899, 'learning_rate': 1.763157894736842e-05, 'epoch': 66.5}\n",
      "{'loss': 0.0212, 'learning_rate': 1.736842105263158e-05, 'epoch': 67.0}\n",
      "{'loss': 0.0442, 'learning_rate': 1.7105263157894737e-05, 'epoch': 67.5}\n",
      "{'loss': 0.2269, 'learning_rate': 1.6842105263157896e-05, 'epoch': 68.0}\n",
      "{'loss': 0.1765, 'learning_rate': 1.6578947368421053e-05, 'epoch': 68.5}\n",
      "{'loss': 0.06, 'learning_rate': 1.6315789473684213e-05, 'epoch': 69.0}\n",
      "{'loss': 0.0969, 'learning_rate': 1.605263157894737e-05, 'epoch': 69.5}\n",
      "{'loss': 0.1528, 'learning_rate': 1.5789473684210526e-05, 'epoch': 70.0}\n",
      "{'loss': 0.1163, 'learning_rate': 1.5526315789473686e-05, 'epoch': 70.5}\n",
      "{'loss': 0.1568, 'learning_rate': 1.5263157894736842e-05, 'epoch': 71.0}\n",
      "{'loss': 0.1006, 'learning_rate': 1.5e-05, 'epoch': 71.5}\n",
      "{'loss': 0.1182, 'learning_rate': 1.4736842105263157e-05, 'epoch': 72.0}\n",
      "{'loss': 0.1195, 'learning_rate': 1.4473684210526317e-05, 'epoch': 72.5}\n",
      "{'loss': 0.1141, 'learning_rate': 1.4210526315789475e-05, 'epoch': 73.0}\n",
      "{'loss': 0.1018, 'learning_rate': 1.3947368421052631e-05, 'epoch': 73.5}\n",
      "{'loss': 0.1421, 'learning_rate': 1.3684210526315791e-05, 'epoch': 74.0}\n",
      "{'loss': 0.1236, 'learning_rate': 1.3421052631578948e-05, 'epoch': 74.5}\n",
      "{'loss': 0.1081, 'learning_rate': 1.3157894736842106e-05, 'epoch': 75.0}\n",
      "{'loss': 0.107, 'learning_rate': 1.2894736842105264e-05, 'epoch': 75.5}\n",
      "{'loss': 0.1168, 'learning_rate': 1.2631578947368422e-05, 'epoch': 76.0}\n",
      "{'loss': 0.1015, 'learning_rate': 1.2368421052631579e-05, 'epoch': 76.5}\n",
      "{'loss': 0.1072, 'learning_rate': 1.2105263157894737e-05, 'epoch': 77.0}\n",
      "{'loss': 0.1116, 'learning_rate': 1.1842105263157895e-05, 'epoch': 77.5}\n",
      "{'loss': 0.1376, 'learning_rate': 1.1578947368421053e-05, 'epoch': 78.0}\n",
      "{'loss': 0.1802, 'learning_rate': 1.1315789473684212e-05, 'epoch': 78.5}\n",
      "{'loss': 0.0404, 'learning_rate': 1.1052631578947368e-05, 'epoch': 79.0}\n",
      "{'loss': 0.0907, 'learning_rate': 1.0789473684210526e-05, 'epoch': 79.5}\n",
      "{'loss': 0.1351, 'learning_rate': 1.0526315789473684e-05, 'epoch': 80.0}\n",
      "{'loss': 0.0954, 'learning_rate': 1.0263157894736843e-05, 'epoch': 80.5}\n",
      "{'loss': 0.1421, 'learning_rate': 1e-05, 'epoch': 81.0}\n",
      "{'loss': 0.1115, 'learning_rate': 9.736842105263157e-06, 'epoch': 81.5}\n",
      "{'loss': 0.1318, 'learning_rate': 9.473684210526317e-06, 'epoch': 82.0}\n",
      "{'loss': 0.1353, 'learning_rate': 9.210526315789474e-06, 'epoch': 82.5}\n",
      "{'loss': 0.0768, 'learning_rate': 8.947368421052632e-06, 'epoch': 83.0}\n",
      "{'loss': 0.1226, 'learning_rate': 8.68421052631579e-06, 'epoch': 83.5}\n",
      "{'loss': 0.1023, 'learning_rate': 8.421052631578948e-06, 'epoch': 84.0}\n",
      "{'loss': 0.1578, 'learning_rate': 8.157894736842106e-06, 'epoch': 84.5}\n",
      "{'loss': 0.0411, 'learning_rate': 7.894736842105263e-06, 'epoch': 85.0}\n",
      "{'loss': 0.1433, 'learning_rate': 7.631578947368421e-06, 'epoch': 85.5}\n",
      "{'loss': 0.0804, 'learning_rate': 7.3684210526315784e-06, 'epoch': 86.0}\n",
      "{'loss': 0.1483, 'learning_rate': 7.1052631578947375e-06, 'epoch': 86.5}\n",
      "{'loss': 0.0775, 'learning_rate': 6.842105263157896e-06, 'epoch': 87.0}\n",
      "{'loss': 0.0656, 'learning_rate': 6.578947368421053e-06, 'epoch': 87.5}\n",
      "{'loss': 0.1678, 'learning_rate': 6.315789473684211e-06, 'epoch': 88.0}\n",
      "{'loss': 0.0901, 'learning_rate': 6.0526315789473685e-06, 'epoch': 88.5}\n",
      "{'loss': 0.1644, 'learning_rate': 5.789473684210527e-06, 'epoch': 89.0}\n",
      "{'loss': 0.1347, 'learning_rate': 5.526315789473684e-06, 'epoch': 89.5}\n",
      "{'loss': 0.1001, 'learning_rate': 5.263157894736842e-06, 'epoch': 90.0}\n",
      "{'loss': 0.0559, 'learning_rate': 5e-06, 'epoch': 90.5}\n",
      "{'loss': 0.1919, 'learning_rate': 4.736842105263159e-06, 'epoch': 91.0}\n",
      "{'loss': 0.0163, 'learning_rate': 4.473684210526316e-06, 'epoch': 91.5}\n",
      "{'loss': 0.2675, 'learning_rate': 4.210526315789474e-06, 'epoch': 92.0}\n",
      "{'loss': 0.077, 'learning_rate': 3.9473684210526315e-06, 'epoch': 92.5}\n",
      "{'loss': 0.1873, 'learning_rate': 3.6842105263157892e-06, 'epoch': 93.0}\n",
      "{'loss': 0.1678, 'learning_rate': 3.421052631578948e-06, 'epoch': 93.5}\n",
      "{'loss': 0.0369, 'learning_rate': 3.1578947368421056e-06, 'epoch': 94.0}\n",
      "{'loss': 0.0879, 'learning_rate': 2.8947368421052634e-06, 'epoch': 94.5}\n",
      "{'loss': 0.1652, 'learning_rate': 2.631578947368421e-06, 'epoch': 95.0}\n",
      "{'loss': 0.1379, 'learning_rate': 2.3684210526315793e-06, 'epoch': 95.5}\n",
      "{'loss': 0.085, 'learning_rate': 2.105263157894737e-06, 'epoch': 96.0}\n",
      "{'loss': 0.1435, 'learning_rate': 1.8421052631578946e-06, 'epoch': 96.5}\n",
      "{'loss': 0.0887, 'learning_rate': 1.5789473684210528e-06, 'epoch': 97.0}\n",
      "{'loss': 0.1114, 'learning_rate': 1.3157894736842106e-06, 'epoch': 97.5}\n",
      "{'loss': 0.1541, 'learning_rate': 1.0526315789473685e-06, 'epoch': 98.0}\n",
      "{'loss': 0.1045, 'learning_rate': 7.894736842105264e-07, 'epoch': 98.5}\n",
      "{'loss': 0.1183, 'learning_rate': 5.263157894736843e-07, 'epoch': 99.0}\n",
      "{'loss': 0.1048, 'learning_rate': 2.6315789473684213e-07, 'epoch': 99.5}\n",
      "{'loss': 0.1262, 'learning_rate': 0.0, 'epoch': 100.0}\n",
      "{'train_runtime': 909.9684, 'train_samples_per_second': 5.934, 'train_steps_per_second': 0.22, 'train_loss': 0.22504198064096273, 'epoch': 100.0}\n",
      "Fitting model using fold 1 as out of fold data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at kiddothe2b/longformer-mini-1024 were not used when initializing LongformerForSequenceClassification: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.bias', 'longformer.embeddings.position_ids']\n",
      "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at kiddothe2b/longformer-mini-1024 and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/57 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6798, 'learning_rate': 5e-06, 'epoch': 0.5}\n",
      "{'loss': 0.6816, 'learning_rate': 1e-05, 'epoch': 1.0}\n",
      "{'loss': 0.6954, 'learning_rate': 1.5e-05, 'epoch': 1.5}\n",
      "{'loss': 0.6815, 'learning_rate': 2e-05, 'epoch': 2.0}\n",
      "{'loss': 0.6849, 'learning_rate': 2.5e-05, 'epoch': 2.5}\n",
      "{'loss': 0.6762, 'learning_rate': 3e-05, 'epoch': 3.0}\n",
      "{'loss': 0.6759, 'learning_rate': 3.5e-05, 'epoch': 3.5}\n",
      "{'loss': 0.6771, 'learning_rate': 4e-05, 'epoch': 4.0}\n",
      "{'loss': 0.6682, 'learning_rate': 4.5e-05, 'epoch': 4.5}\n",
      "{'loss': 0.6837, 'learning_rate': 5e-05, 'epoch': 5.0}\n",
      "{'loss': 0.695, 'learning_rate': 4.973684210526316e-05, 'epoch': 5.5}\n",
      "{'loss': 0.6241, 'learning_rate': 4.9473684210526315e-05, 'epoch': 6.0}\n",
      "{'loss': 0.6768, 'learning_rate': 4.921052631578947e-05, 'epoch': 6.5}\n",
      "{'loss': 0.6314, 'learning_rate': 4.8947368421052635e-05, 'epoch': 7.0}\n",
      "{'loss': 0.656, 'learning_rate': 4.868421052631579e-05, 'epoch': 7.5}\n",
      "{'loss': 0.6294, 'learning_rate': 4.842105263157895e-05, 'epoch': 8.0}\n",
      "{'loss': 0.6257, 'learning_rate': 4.8157894736842105e-05, 'epoch': 8.5}\n",
      "{'loss': 0.6244, 'learning_rate': 4.789473684210526e-05, 'epoch': 9.0}\n",
      "{'loss': 0.6093, 'learning_rate': 4.7631578947368424e-05, 'epoch': 9.5}\n",
      "{'loss': 0.6067, 'learning_rate': 4.736842105263158e-05, 'epoch': 10.0}\n",
      "{'loss': 0.5958, 'learning_rate': 4.7105263157894744e-05, 'epoch': 10.5}\n",
      "{'loss': 0.5651, 'learning_rate': 4.68421052631579e-05, 'epoch': 11.0}\n",
      "{'loss': 0.5425, 'learning_rate': 4.657894736842106e-05, 'epoch': 11.5}\n",
      "{'loss': 0.5427, 'learning_rate': 4.6315789473684214e-05, 'epoch': 12.0}\n",
      "{'loss': 0.5235, 'learning_rate': 4.605263157894737e-05, 'epoch': 12.5}\n",
      "{'loss': 0.513, 'learning_rate': 4.5789473684210527e-05, 'epoch': 13.0}\n",
      "{'loss': 0.4661, 'learning_rate': 4.552631578947369e-05, 'epoch': 13.5}\n",
      "{'loss': 0.505, 'learning_rate': 4.5263157894736846e-05, 'epoch': 14.0}\n",
      "{'loss': 0.4406, 'learning_rate': 4.5e-05, 'epoch': 14.5}\n",
      "{'loss': 0.474, 'learning_rate': 4.473684210526316e-05, 'epoch': 15.0}\n",
      "{'loss': 0.4479, 'learning_rate': 4.4473684210526316e-05, 'epoch': 15.5}\n",
      "{'loss': 0.3547, 'learning_rate': 4.421052631578947e-05, 'epoch': 16.0}\n",
      "{'loss': 0.4193, 'learning_rate': 4.394736842105263e-05, 'epoch': 16.5}\n",
      "{'loss': 0.3533, 'learning_rate': 4.368421052631579e-05, 'epoch': 17.0}\n",
      "{'loss': 0.3852, 'learning_rate': 4.342105263157895e-05, 'epoch': 17.5}\n",
      "{'loss': 0.3542, 'learning_rate': 4.3157894736842105e-05, 'epoch': 18.0}\n",
      "{'loss': 0.3513, 'learning_rate': 4.289473684210527e-05, 'epoch': 18.5}\n",
      "{'loss': 0.3239, 'learning_rate': 4.2631578947368425e-05, 'epoch': 19.0}\n",
      "{'loss': 0.3652, 'learning_rate': 4.236842105263158e-05, 'epoch': 19.5}\n",
      "{'loss': 0.2581, 'learning_rate': 4.210526315789474e-05, 'epoch': 20.0}\n",
      "{'loss': 0.3539, 'learning_rate': 4.18421052631579e-05, 'epoch': 20.5}\n",
      "{'loss': 0.2544, 'learning_rate': 4.157894736842106e-05, 'epoch': 21.0}\n",
      "{'loss': 0.3166, 'learning_rate': 4.1315789473684214e-05, 'epoch': 21.5}\n",
      "{'loss': 0.2419, 'learning_rate': 4.105263157894737e-05, 'epoch': 22.0}\n",
      "{'loss': 0.2544, 'learning_rate': 4.078947368421053e-05, 'epoch': 22.5}\n",
      "{'loss': 0.2489, 'learning_rate': 4.0526315789473684e-05, 'epoch': 23.0}\n",
      "{'loss': 0.2819, 'learning_rate': 4.026315789473684e-05, 'epoch': 23.5}\n",
      "{'loss': 0.2199, 'learning_rate': 4e-05, 'epoch': 24.0}\n",
      "{'loss': 0.2399, 'learning_rate': 3.973684210526316e-05, 'epoch': 24.5}\n",
      "{'loss': 0.2324, 'learning_rate': 3.9473684210526316e-05, 'epoch': 25.0}\n",
      "{'loss': 0.2158, 'learning_rate': 3.921052631578947e-05, 'epoch': 25.5}\n",
      "{'loss': 0.2454, 'learning_rate': 3.894736842105263e-05, 'epoch': 26.0}\n",
      "{'loss': 0.2189, 'learning_rate': 3.868421052631579e-05, 'epoch': 26.5}\n",
      "{'loss': 0.2439, 'learning_rate': 3.842105263157895e-05, 'epoch': 27.0}\n",
      "{'loss': 0.1874, 'learning_rate': 3.815789473684211e-05, 'epoch': 27.5}\n",
      "{'loss': 0.2345, 'learning_rate': 3.789473684210527e-05, 'epoch': 28.0}\n",
      "{'loss': 0.191, 'learning_rate': 3.7631578947368425e-05, 'epoch': 28.5}\n",
      "{'loss': 0.2211, 'learning_rate': 3.736842105263158e-05, 'epoch': 29.0}\n",
      "{'loss': 0.1499, 'learning_rate': 3.710526315789474e-05, 'epoch': 29.5}\n",
      "{'loss': 0.2296, 'learning_rate': 3.6842105263157895e-05, 'epoch': 30.0}\n",
      "{'loss': 0.225, 'learning_rate': 3.657894736842106e-05, 'epoch': 30.5}\n",
      "{'loss': 0.1707, 'learning_rate': 3.6315789473684214e-05, 'epoch': 31.0}\n",
      "{'loss': 0.14, 'learning_rate': 3.605263157894737e-05, 'epoch': 31.5}\n",
      "{'loss': 0.2476, 'learning_rate': 3.578947368421053e-05, 'epoch': 32.0}\n",
      "{'loss': 0.18, 'learning_rate': 3.5526315789473684e-05, 'epoch': 32.5}\n",
      "{'loss': 0.206, 'learning_rate': 3.526315789473684e-05, 'epoch': 33.0}\n",
      "{'loss': 0.1798, 'learning_rate': 3.5e-05, 'epoch': 33.5}\n",
      "{'loss': 0.2113, 'learning_rate': 3.473684210526316e-05, 'epoch': 34.0}\n",
      "{'loss': 0.1912, 'learning_rate': 3.447368421052632e-05, 'epoch': 34.5}\n",
      "{'loss': 0.158, 'learning_rate': 3.421052631578947e-05, 'epoch': 35.0}\n",
      "{'loss': 0.2156, 'learning_rate': 3.3947368421052636e-05, 'epoch': 35.5}\n",
      "{'loss': 0.1326, 'learning_rate': 3.368421052631579e-05, 'epoch': 36.0}\n",
      "{'loss': 0.2178, 'learning_rate': 3.342105263157895e-05, 'epoch': 36.5}\n",
      "{'loss': 0.1249, 'learning_rate': 3.3157894736842106e-05, 'epoch': 37.0}\n",
      "{'loss': 0.1988, 'learning_rate': 3.289473684210527e-05, 'epoch': 37.5}\n",
      "{'loss': 0.1481, 'learning_rate': 3.2631578947368426e-05, 'epoch': 38.0}\n",
      "{'loss': 0.1948, 'learning_rate': 3.236842105263158e-05, 'epoch': 38.5}\n",
      "{'loss': 0.1374, 'learning_rate': 3.210526315789474e-05, 'epoch': 39.0}\n",
      "{'loss': 0.1694, 'learning_rate': 3.1842105263157895e-05, 'epoch': 39.5}\n",
      "{'loss': 0.178, 'learning_rate': 3.157894736842105e-05, 'epoch': 40.0}\n",
      "{'loss': 0.161, 'learning_rate': 3.131578947368421e-05, 'epoch': 40.5}\n",
      "{'loss': 0.1874, 'learning_rate': 3.105263157894737e-05, 'epoch': 41.0}\n",
      "{'loss': 0.0977, 'learning_rate': 3.078947368421053e-05, 'epoch': 41.5}\n",
      "{'loss': 0.2539, 'learning_rate': 3.0526315789473684e-05, 'epoch': 42.0}\n",
      "{'loss': 0.1185, 'learning_rate': 3.0263157894736844e-05, 'epoch': 42.5}\n",
      "{'loss': 0.2141, 'learning_rate': 3e-05, 'epoch': 43.0}\n",
      "{'loss': 0.0691, 'learning_rate': 2.9736842105263157e-05, 'epoch': 43.5}\n",
      "{'loss': 0.2682, 'learning_rate': 2.9473684210526314e-05, 'epoch': 44.0}\n",
      "{'loss': 0.1529, 'learning_rate': 2.9210526315789477e-05, 'epoch': 44.5}\n",
      "{'loss': 0.1658, 'learning_rate': 2.8947368421052634e-05, 'epoch': 45.0}\n",
      "{'loss': 0.1893, 'learning_rate': 2.868421052631579e-05, 'epoch': 45.5}\n",
      "{'loss': 0.1374, 'learning_rate': 2.842105263157895e-05, 'epoch': 46.0}\n",
      "{'loss': 0.1534, 'learning_rate': 2.8157894736842106e-05, 'epoch': 46.5}\n",
      "{'loss': 0.1854, 'learning_rate': 2.7894736842105263e-05, 'epoch': 47.0}\n",
      "{'loss': 0.1211, 'learning_rate': 2.7631578947368426e-05, 'epoch': 47.5}\n",
      "{'loss': 0.2073, 'learning_rate': 2.7368421052631583e-05, 'epoch': 48.0}\n",
      "{'loss': 0.1373, 'learning_rate': 2.710526315789474e-05, 'epoch': 48.5}\n",
      "{'loss': 0.1948, 'learning_rate': 2.6842105263157896e-05, 'epoch': 49.0}\n",
      "{'loss': 0.1056, 'learning_rate': 2.6578947368421052e-05, 'epoch': 49.5}\n",
      "{'loss': 0.1951, 'learning_rate': 2.6315789473684212e-05, 'epoch': 50.0}\n",
      "{'loss': 0.1419, 'learning_rate': 2.605263157894737e-05, 'epoch': 50.5}\n",
      "{'loss': 0.1728, 'learning_rate': 2.578947368421053e-05, 'epoch': 51.0}\n",
      "{'loss': 0.1776, 'learning_rate': 2.5526315789473688e-05, 'epoch': 51.5}\n",
      "{'loss': 0.1342, 'learning_rate': 2.5263157894736845e-05, 'epoch': 52.0}\n",
      "{'loss': 0.1263, 'learning_rate': 2.5e-05, 'epoch': 52.5}\n",
      "{'loss': 0.2025, 'learning_rate': 2.4736842105263158e-05, 'epoch': 53.0}\n",
      "{'loss': 0.239, 'learning_rate': 2.4473684210526318e-05, 'epoch': 53.5}\n",
      "{'loss': 0.0776, 'learning_rate': 2.4210526315789474e-05, 'epoch': 54.0}\n",
      "{'loss': 0.1796, 'learning_rate': 2.394736842105263e-05, 'epoch': 54.5}\n",
      "{'loss': 0.132, 'learning_rate': 2.368421052631579e-05, 'epoch': 55.0}\n",
      "{'loss': 0.1405, 'learning_rate': 2.342105263157895e-05, 'epoch': 55.5}\n",
      "{'loss': 0.1629, 'learning_rate': 2.3157894736842107e-05, 'epoch': 56.0}\n",
      "{'loss': 0.1554, 'learning_rate': 2.2894736842105263e-05, 'epoch': 56.5}\n",
      "{'loss': 0.1598, 'learning_rate': 2.2631578947368423e-05, 'epoch': 57.0}\n",
      "{'loss': 0.1791, 'learning_rate': 2.236842105263158e-05, 'epoch': 57.5}\n",
      "{'loss': 0.1301, 'learning_rate': 2.2105263157894736e-05, 'epoch': 58.0}\n",
      "{'loss': 0.2147, 'learning_rate': 2.1842105263157896e-05, 'epoch': 58.5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0802, 'learning_rate': 2.1578947368421053e-05, 'epoch': 59.0}\n",
      "{'loss': 0.0877, 'learning_rate': 2.1315789473684212e-05, 'epoch': 59.5}\n",
      "{'loss': 0.2442, 'learning_rate': 2.105263157894737e-05, 'epoch': 60.0}\n",
      "{'loss': 0.1436, 'learning_rate': 2.078947368421053e-05, 'epoch': 60.5}\n",
      "{'loss': 0.1696, 'learning_rate': 2.0526315789473685e-05, 'epoch': 61.0}\n",
      "{'loss': 0.2064, 'learning_rate': 2.0263157894736842e-05, 'epoch': 61.5}\n",
      "{'loss': 0.0757, 'learning_rate': 2e-05, 'epoch': 62.0}\n",
      "{'loss': 0.1516, 'learning_rate': 1.9736842105263158e-05, 'epoch': 62.5}\n",
      "{'loss': 0.1529, 'learning_rate': 1.9473684210526315e-05, 'epoch': 63.0}\n",
      "{'loss': 0.1866, 'learning_rate': 1.9210526315789474e-05, 'epoch': 63.5}\n",
      "{'loss': 0.1204, 'learning_rate': 1.8947368421052634e-05, 'epoch': 64.0}\n",
      "{'loss': 0.1489, 'learning_rate': 1.868421052631579e-05, 'epoch': 64.5}\n",
      "{'loss': 0.1538, 'learning_rate': 1.8421052631578947e-05, 'epoch': 65.0}\n",
      "{'loss': 0.1274, 'learning_rate': 1.8157894736842107e-05, 'epoch': 65.5}\n",
      "{'loss': 0.1679, 'learning_rate': 1.7894736842105264e-05, 'epoch': 66.0}\n",
      "{'loss': 0.1856, 'learning_rate': 1.763157894736842e-05, 'epoch': 66.5}\n",
      "{'loss': 0.2592, 'learning_rate': 1.736842105263158e-05, 'epoch': 67.0}\n",
      "{'loss': 0.1689, 'learning_rate': 1.7105263157894737e-05, 'epoch': 67.5}\n",
      "{'loss': 0.1386, 'learning_rate': 1.6842105263157896e-05, 'epoch': 68.0}\n",
      "{'loss': 0.1744, 'learning_rate': 1.6578947368421053e-05, 'epoch': 68.5}\n",
      "{'loss': 0.106, 'learning_rate': 1.6315789473684213e-05, 'epoch': 69.0}\n",
      "{'loss': 0.092, 'learning_rate': 1.605263157894737e-05, 'epoch': 69.5}\n",
      "{'loss': 0.2051, 'learning_rate': 1.5789473684210526e-05, 'epoch': 70.0}\n",
      "{'loss': 0.2103, 'learning_rate': 1.5526315789473686e-05, 'epoch': 70.5}\n",
      "{'loss': 0.0675, 'learning_rate': 1.5263157894736842e-05, 'epoch': 71.0}\n",
      "{'loss': 0.1619, 'learning_rate': 1.5e-05, 'epoch': 71.5}\n",
      "{'loss': 0.1304, 'learning_rate': 1.4736842105263157e-05, 'epoch': 72.0}\n",
      "{'loss': 0.1808, 'learning_rate': 1.4473684210526317e-05, 'epoch': 72.5}\n",
      "{'loss': 0.1272, 'learning_rate': 1.4210526315789475e-05, 'epoch': 73.0}\n",
      "{'loss': 0.1376, 'learning_rate': 1.3947368421052631e-05, 'epoch': 73.5}\n",
      "{'loss': 0.1715, 'learning_rate': 1.3684210526315791e-05, 'epoch': 74.0}\n",
      "{'loss': 0.1944, 'learning_rate': 1.3421052631578948e-05, 'epoch': 74.5}\n",
      "{'loss': 0.0757, 'learning_rate': 1.3157894736842106e-05, 'epoch': 75.0}\n",
      "{'loss': 0.1498, 'learning_rate': 1.2894736842105264e-05, 'epoch': 75.5}\n",
      "{'loss': 0.1458, 'learning_rate': 1.2631578947368422e-05, 'epoch': 76.0}\n",
      "{'loss': 0.1484, 'learning_rate': 1.2368421052631579e-05, 'epoch': 76.5}\n",
      "{'loss': 0.119, 'learning_rate': 1.2105263157894737e-05, 'epoch': 77.0}\n",
      "{'loss': 0.1605, 'learning_rate': 1.1842105263157895e-05, 'epoch': 77.5}\n",
      "{'loss': 0.1321, 'learning_rate': 1.1578947368421053e-05, 'epoch': 78.0}\n",
      "{'loss': 0.1431, 'learning_rate': 1.1315789473684212e-05, 'epoch': 78.5}\n",
      "{'loss': 0.1475, 'learning_rate': 1.1052631578947368e-05, 'epoch': 79.0}\n",
      "{'loss': 0.1508, 'learning_rate': 1.0789473684210526e-05, 'epoch': 79.5}\n",
      "{'loss': 0.1326, 'learning_rate': 1.0526315789473684e-05, 'epoch': 80.0}\n",
      "{'loss': 0.1897, 'learning_rate': 1.0263157894736843e-05, 'epoch': 80.5}\n",
      "{'loss': 0.0888, 'learning_rate': 1e-05, 'epoch': 81.0}\n",
      "{'loss': 0.0999, 'learning_rate': 9.736842105263157e-06, 'epoch': 81.5}\n",
      "{'loss': 0.2248, 'learning_rate': 9.473684210526317e-06, 'epoch': 82.0}\n",
      "{'loss': 0.208, 'learning_rate': 9.210526315789474e-06, 'epoch': 82.5}\n",
      "{'loss': 0.0851, 'learning_rate': 8.947368421052632e-06, 'epoch': 83.0}\n",
      "{'loss': 0.1586, 'learning_rate': 8.68421052631579e-06, 'epoch': 83.5}\n",
      "{'loss': 0.148, 'learning_rate': 8.421052631578948e-06, 'epoch': 84.0}\n",
      "{'loss': 0.1633, 'learning_rate': 8.157894736842106e-06, 'epoch': 84.5}\n",
      "{'loss': 0.1587, 'learning_rate': 7.894736842105263e-06, 'epoch': 85.0}\n",
      "{'loss': 0.1633, 'learning_rate': 7.631578947368421e-06, 'epoch': 85.5}\n",
      "{'loss': 0.1216, 'learning_rate': 7.3684210526315784e-06, 'epoch': 86.0}\n",
      "{'loss': 0.184, 'learning_rate': 7.1052631578947375e-06, 'epoch': 86.5}\n",
      "{'loss': 0.1063, 'learning_rate': 6.842105263157896e-06, 'epoch': 87.0}\n",
      "{'loss': 0.1257, 'learning_rate': 6.578947368421053e-06, 'epoch': 87.5}\n",
      "{'loss': 0.1999, 'learning_rate': 6.315789473684211e-06, 'epoch': 88.0}\n",
      "{'loss': 0.1937, 'learning_rate': 6.0526315789473685e-06, 'epoch': 88.5}\n",
      "{'loss': 0.1068, 'learning_rate': 5.789473684210527e-06, 'epoch': 89.0}\n",
      "{'loss': 0.1368, 'learning_rate': 5.526315789473684e-06, 'epoch': 89.5}\n",
      "{'loss': 0.1642, 'learning_rate': 5.263157894736842e-06, 'epoch': 90.0}\n",
      "{'loss': 0.0991, 'learning_rate': 5e-06, 'epoch': 90.5}\n",
      "{'loss': 0.2191, 'learning_rate': 4.736842105263159e-06, 'epoch': 91.0}\n",
      "{'loss': 0.145, 'learning_rate': 4.473684210526316e-06, 'epoch': 91.5}\n",
      "{'loss': 0.1192, 'learning_rate': 4.210526315789474e-06, 'epoch': 92.0}\n",
      "{'loss': 0.1873, 'learning_rate': 3.9473684210526315e-06, 'epoch': 92.5}\n",
      "{'loss': 0.0937, 'learning_rate': 3.6842105263157892e-06, 'epoch': 93.0}\n",
      "{'loss': 0.1579, 'learning_rate': 3.421052631578948e-06, 'epoch': 93.5}\n",
      "{'loss': 0.1263, 'learning_rate': 3.1578947368421056e-06, 'epoch': 94.0}\n",
      "{'loss': 0.1035, 'learning_rate': 2.8947368421052634e-06, 'epoch': 94.5}\n",
      "{'loss': 0.192, 'learning_rate': 2.631578947368421e-06, 'epoch': 95.0}\n",
      "{'loss': 0.1004, 'learning_rate': 2.3684210526315793e-06, 'epoch': 95.5}\n",
      "{'loss': 0.2139, 'learning_rate': 2.105263157894737e-06, 'epoch': 96.0}\n",
      "{'loss': 0.164, 'learning_rate': 1.8421052631578946e-06, 'epoch': 96.5}\n",
      "{'loss': 0.1095, 'learning_rate': 1.5789473684210528e-06, 'epoch': 97.0}\n",
      "{'loss': 0.1924, 'learning_rate': 1.3157894736842106e-06, 'epoch': 97.5}\n",
      "{'loss': 0.1024, 'learning_rate': 1.0526315789473685e-06, 'epoch': 98.0}\n",
      "{'loss': 0.1514, 'learning_rate': 7.894736842105264e-07, 'epoch': 98.5}\n",
      "{'loss': 0.1265, 'learning_rate': 5.263157894736843e-07, 'epoch': 99.0}\n",
      "{'loss': 0.1498, 'learning_rate': 2.6315789473684213e-07, 'epoch': 99.5}\n",
      "{'loss': 0.1472, 'learning_rate': 0.0, 'epoch': 100.0}\n",
      "{'train_runtime': 944.8023, 'train_samples_per_second': 6.033, 'train_steps_per_second': 0.212, 'train_loss': 0.24387632854282856, 'epoch': 100.0}\n",
      "Fitting model using fold 2 as out of fold data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at kiddothe2b/longformer-mini-1024 were not used when initializing LongformerForSequenceClassification: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.bias', 'longformer.embeddings.position_ids']\n",
      "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at kiddothe2b/longformer-mini-1024 and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/57 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6936, 'learning_rate': 5e-06, 'epoch': 0.5}\n",
      "{'loss': 0.6873, 'learning_rate': 1e-05, 'epoch': 1.0}\n",
      "{'loss': 0.7067, 'learning_rate': 1.5e-05, 'epoch': 1.5}\n",
      "{'loss': 0.6952, 'learning_rate': 2e-05, 'epoch': 2.0}\n",
      "{'loss': 0.6913, 'learning_rate': 2.5e-05, 'epoch': 2.5}\n",
      "{'loss': 0.6817, 'learning_rate': 3e-05, 'epoch': 3.0}\n",
      "{'loss': 0.6844, 'learning_rate': 3.5e-05, 'epoch': 3.5}\n",
      "{'loss': 0.6789, 'learning_rate': 4e-05, 'epoch': 4.0}\n",
      "{'loss': 0.6784, 'learning_rate': 4.5e-05, 'epoch': 4.5}\n",
      "{'loss': 0.6648, 'learning_rate': 5e-05, 'epoch': 5.0}\n",
      "{'loss': 0.6612, 'learning_rate': 4.973684210526316e-05, 'epoch': 5.5}\n",
      "{'loss': 0.6731, 'learning_rate': 4.9473684210526315e-05, 'epoch': 6.0}\n",
      "{'loss': 0.6531, 'learning_rate': 4.921052631578947e-05, 'epoch': 6.5}\n",
      "{'loss': 0.6617, 'learning_rate': 4.8947368421052635e-05, 'epoch': 7.0}\n",
      "{'loss': 0.6691, 'learning_rate': 4.868421052631579e-05, 'epoch': 7.5}\n",
      "{'loss': 0.6201, 'learning_rate': 4.842105263157895e-05, 'epoch': 8.0}\n",
      "{'loss': 0.6208, 'learning_rate': 4.8157894736842105e-05, 'epoch': 8.5}\n",
      "{'loss': 0.6366, 'learning_rate': 4.789473684210526e-05, 'epoch': 9.0}\n",
      "{'loss': 0.6016, 'learning_rate': 4.7631578947368424e-05, 'epoch': 9.5}\n",
      "{'loss': 0.6256, 'learning_rate': 4.736842105263158e-05, 'epoch': 10.0}\n",
      "{'loss': 0.6153, 'learning_rate': 4.7105263157894744e-05, 'epoch': 10.5}\n",
      "{'loss': 0.5538, 'learning_rate': 4.68421052631579e-05, 'epoch': 11.0}\n",
      "{'loss': 0.5885, 'learning_rate': 4.657894736842106e-05, 'epoch': 11.5}\n",
      "{'loss': 0.533, 'learning_rate': 4.6315789473684214e-05, 'epoch': 12.0}\n",
      "{'loss': 0.5311, 'learning_rate': 4.605263157894737e-05, 'epoch': 12.5}\n",
      "{'loss': 0.5132, 'learning_rate': 4.5789473684210527e-05, 'epoch': 13.0}\n",
      "{'loss': 0.4765, 'learning_rate': 4.552631578947369e-05, 'epoch': 13.5}\n",
      "{'loss': 0.5427, 'learning_rate': 4.5263157894736846e-05, 'epoch': 14.0}\n",
      "{'loss': 0.4588, 'learning_rate': 4.5e-05, 'epoch': 14.5}\n",
      "{'loss': 0.4715, 'learning_rate': 4.473684210526316e-05, 'epoch': 15.0}\n",
      "{'loss': 0.4726, 'learning_rate': 4.4473684210526316e-05, 'epoch': 15.5}\n",
      "{'loss': 0.3608, 'learning_rate': 4.421052631578947e-05, 'epoch': 16.0}\n",
      "{'loss': 0.4432, 'learning_rate': 4.394736842105263e-05, 'epoch': 16.5}\n",
      "{'loss': 0.3104, 'learning_rate': 4.368421052631579e-05, 'epoch': 17.0}\n",
      "{'loss': 0.3764, 'learning_rate': 4.342105263157895e-05, 'epoch': 17.5}\n",
      "{'loss': 0.3452, 'learning_rate': 4.3157894736842105e-05, 'epoch': 18.0}\n",
      "{'loss': 0.3352, 'learning_rate': 4.289473684210527e-05, 'epoch': 18.5}\n",
      "{'loss': 0.3101, 'learning_rate': 4.2631578947368425e-05, 'epoch': 19.0}\n",
      "{'loss': 0.3208, 'learning_rate': 4.236842105263158e-05, 'epoch': 19.5}\n",
      "{'loss': 0.2813, 'learning_rate': 4.210526315789474e-05, 'epoch': 20.0}\n",
      "{'loss': 0.3456, 'learning_rate': 4.18421052631579e-05, 'epoch': 20.5}\n",
      "{'loss': 0.2037, 'learning_rate': 4.157894736842106e-05, 'epoch': 21.0}\n",
      "{'loss': 0.312, 'learning_rate': 4.1315789473684214e-05, 'epoch': 21.5}\n",
      "{'loss': 0.2423, 'learning_rate': 4.1315789473684214e-05, 'epoch': 22.0}\n",
      "{'loss': 0.2758, 'learning_rate': 4.105263157894737e-05, 'epoch': 22.5}\n",
      "{'loss': 0.2274, 'learning_rate': 4.078947368421053e-05, 'epoch': 23.0}\n",
      "{'loss': 0.263, 'learning_rate': 4.0526315789473684e-05, 'epoch': 23.5}\n",
      "{'loss': 0.2062, 'learning_rate': 4.026315789473684e-05, 'epoch': 24.0}\n",
      "{'loss': 0.1891, 'learning_rate': 4e-05, 'epoch': 24.5}\n",
      "{'loss': 0.2615, 'learning_rate': 3.973684210526316e-05, 'epoch': 25.0}\n",
      "{'loss': 0.2267, 'learning_rate': 3.9473684210526316e-05, 'epoch': 25.5}\n",
      "{'loss': 0.1918, 'learning_rate': 3.921052631578947e-05, 'epoch': 26.0}\n",
      "{'loss': 0.1806, 'learning_rate': 3.894736842105263e-05, 'epoch': 26.5}\n",
      "{'loss': 0.2472, 'learning_rate': 3.868421052631579e-05, 'epoch': 27.0}\n",
      "{'loss': 0.1984, 'learning_rate': 3.842105263157895e-05, 'epoch': 27.5}\n",
      "{'loss': 0.1746, 'learning_rate': 3.815789473684211e-05, 'epoch': 28.0}\n",
      "{'loss': 0.1607, 'learning_rate': 3.789473684210527e-05, 'epoch': 28.5}\n",
      "{'loss': 0.2378, 'learning_rate': 3.7631578947368425e-05, 'epoch': 29.0}\n",
      "{'loss': 0.1318, 'learning_rate': 3.736842105263158e-05, 'epoch': 29.5}\n",
      "{'loss': 0.197, 'learning_rate': 3.710526315789474e-05, 'epoch': 30.0}\n",
      "{'loss': 0.184, 'learning_rate': 3.6842105263157895e-05, 'epoch': 30.5}\n",
      "{'loss': 0.1574, 'learning_rate': 3.657894736842106e-05, 'epoch': 31.0}\n",
      "{'loss': 0.1474, 'learning_rate': 3.6315789473684214e-05, 'epoch': 31.5}\n",
      "{'loss': 0.1961, 'learning_rate': 3.605263157894737e-05, 'epoch': 32.0}\n",
      "{'loss': 0.1066, 'learning_rate': 3.578947368421053e-05, 'epoch': 32.5}\n",
      "{'loss': 0.2435, 'learning_rate': 3.5526315789473684e-05, 'epoch': 33.0}\n",
      "{'loss': 0.118, 'learning_rate': 3.526315789473684e-05, 'epoch': 33.5}\n",
      "{'loss': 0.2285, 'learning_rate': 3.5e-05, 'epoch': 34.0}\n",
      "{'loss': 0.1318, 'learning_rate': 3.473684210526316e-05, 'epoch': 34.5}\n",
      "{'loss': 0.1803, 'learning_rate': 3.447368421052632e-05, 'epoch': 35.0}\n",
      "{'loss': 0.1847, 'learning_rate': 3.421052631578947e-05, 'epoch': 35.5}\n",
      "{'loss': 0.1161, 'learning_rate': 3.3947368421052636e-05, 'epoch': 36.0}\n",
      "{'loss': 0.1689, 'learning_rate': 3.368421052631579e-05, 'epoch': 36.5}\n",
      "{'loss': 0.1236, 'learning_rate': 3.342105263157895e-05, 'epoch': 37.0}\n",
      "{'loss': 0.1306, 'learning_rate': 3.3157894736842106e-05, 'epoch': 37.5}\n",
      "{'loss': 0.1729, 'learning_rate': 3.289473684210527e-05, 'epoch': 38.0}\n",
      "{'loss': 0.1471, 'learning_rate': 3.2631578947368426e-05, 'epoch': 38.5}\n",
      "{'loss': 0.1217, 'learning_rate': 3.236842105263158e-05, 'epoch': 39.0}\n",
      "{'loss': 0.114, 'learning_rate': 3.210526315789474e-05, 'epoch': 39.5}\n",
      "{'loss': 0.1642, 'learning_rate': 3.1842105263157895e-05, 'epoch': 40.0}\n",
      "{'loss': 0.1481, 'learning_rate': 3.157894736842105e-05, 'epoch': 40.5}\n",
      "{'loss': 0.1165, 'learning_rate': 3.131578947368421e-05, 'epoch': 41.0}\n",
      "{'loss': 0.1075, 'learning_rate': 3.105263157894737e-05, 'epoch': 41.5}\n",
      "{'loss': 0.178, 'learning_rate': 3.078947368421053e-05, 'epoch': 42.0}\n",
      "{'loss': 0.0589, 'learning_rate': 3.0526315789473684e-05, 'epoch': 42.5}\n",
      "{'loss': 0.227, 'learning_rate': 3.0263157894736844e-05, 'epoch': 43.0}\n",
      "{'loss': 0.0493, 'learning_rate': 3e-05, 'epoch': 43.5}\n",
      "{'loss': 0.2433, 'learning_rate': 2.9736842105263157e-05, 'epoch': 44.0}\n",
      "{'loss': 0.1804, 'learning_rate': 2.9473684210526314e-05, 'epoch': 44.5}\n",
      "{'loss': 0.0689, 'learning_rate': 2.9210526315789477e-05, 'epoch': 45.0}\n",
      "{'loss': 0.1835, 'learning_rate': 2.8947368421052634e-05, 'epoch': 45.5}\n",
      "{'loss': 0.0709, 'learning_rate': 2.868421052631579e-05, 'epoch': 46.0}\n",
      "{'loss': 0.1248, 'learning_rate': 2.842105263157895e-05, 'epoch': 46.5}\n",
      "{'loss': 0.1768, 'learning_rate': 2.8157894736842106e-05, 'epoch': 47.0}\n",
      "{'loss': 0.1337, 'learning_rate': 2.7894736842105263e-05, 'epoch': 47.5}\n",
      "{'loss': 0.1277, 'learning_rate': 2.7631578947368426e-05, 'epoch': 48.0}\n",
      "{'loss': 0.1628, 'learning_rate': 2.7368421052631583e-05, 'epoch': 48.5}\n",
      "{'loss': 0.1205, 'learning_rate': 2.710526315789474e-05, 'epoch': 49.0}\n",
      "{'loss': 0.1134, 'learning_rate': 2.6842105263157896e-05, 'epoch': 49.5}\n",
      "{'loss': 0.1414, 'learning_rate': 2.6578947368421052e-05, 'epoch': 50.0}\n",
      "{'loss': 0.1257, 'learning_rate': 2.6315789473684212e-05, 'epoch': 50.5}\n",
      "{'loss': 0.1652, 'learning_rate': 2.605263157894737e-05, 'epoch': 51.0}\n",
      "{'loss': 0.1542, 'learning_rate': 2.578947368421053e-05, 'epoch': 51.5}\n",
      "{'loss': 0.0958, 'learning_rate': 2.5526315789473688e-05, 'epoch': 52.0}\n",
      "{'loss': 0.1209, 'learning_rate': 2.5263157894736845e-05, 'epoch': 52.5}\n",
      "{'loss': 0.1412, 'learning_rate': 2.5e-05, 'epoch': 53.0}\n",
      "{'loss': 0.1979, 'learning_rate': 2.4736842105263158e-05, 'epoch': 53.5}\n",
      "{'loss': 0.0404, 'learning_rate': 2.4473684210526318e-05, 'epoch': 54.0}\n",
      "{'loss': 0.1318, 'learning_rate': 2.4210526315789474e-05, 'epoch': 54.5}\n",
      "{'loss': 0.127, 'learning_rate': 2.394736842105263e-05, 'epoch': 55.0}\n",
      "{'loss': 0.0907, 'learning_rate': 2.368421052631579e-05, 'epoch': 55.5}\n",
      "{'loss': 0.1735, 'learning_rate': 2.342105263157895e-05, 'epoch': 56.0}\n",
      "{'loss': 0.1172, 'learning_rate': 2.3157894736842107e-05, 'epoch': 56.5}\n",
      "{'loss': 0.1592, 'learning_rate': 2.2894736842105263e-05, 'epoch': 57.0}\n",
      "{'loss': 0.1676, 'learning_rate': 2.2631578947368423e-05, 'epoch': 57.5}\n",
      "{'loss': 0.1073, 'learning_rate': 2.236842105263158e-05, 'epoch': 58.0}\n",
      "{'loss': 0.1884, 'learning_rate': 2.2105263157894736e-05, 'epoch': 58.5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0528, 'learning_rate': 2.1842105263157896e-05, 'epoch': 59.0}\n",
      "{'loss': 0.0687, 'learning_rate': 2.1578947368421053e-05, 'epoch': 59.5}\n",
      "{'loss': 0.1732, 'learning_rate': 2.1315789473684212e-05, 'epoch': 60.0}\n",
      "{'loss': 0.1124, 'learning_rate': 2.105263157894737e-05, 'epoch': 60.5}\n",
      "{'loss': 0.1447, 'learning_rate': 2.078947368421053e-05, 'epoch': 61.0}\n",
      "{'loss': 0.1679, 'learning_rate': 2.0526315789473685e-05, 'epoch': 61.5}\n",
      "{'loss': 0.0594, 'learning_rate': 2.0263157894736842e-05, 'epoch': 62.0}\n",
      "{'loss': 0.1774, 'learning_rate': 2e-05, 'epoch': 62.5}\n",
      "{'loss': 0.0829, 'learning_rate': 1.9736842105263158e-05, 'epoch': 63.0}\n",
      "{'loss': 0.167, 'learning_rate': 1.9473684210526315e-05, 'epoch': 63.5}\n",
      "{'loss': 0.1051, 'learning_rate': 1.9210526315789474e-05, 'epoch': 64.0}\n",
      "{'loss': 0.1288, 'learning_rate': 1.8947368421052634e-05, 'epoch': 64.5}\n",
      "{'loss': 0.1108, 'learning_rate': 1.868421052631579e-05, 'epoch': 65.0}\n",
      "{'loss': 0.1003, 'learning_rate': 1.8421052631578947e-05, 'epoch': 65.5}\n",
      "{'loss': 0.1706, 'learning_rate': 1.8157894736842107e-05, 'epoch': 66.0}\n",
      "{'loss': 0.1635, 'learning_rate': 1.7894736842105264e-05, 'epoch': 66.5}\n",
      "{'loss': 0.0909, 'learning_rate': 1.7894736842105264e-05, 'epoch': 67.0}\n",
      "{'loss': 0.2618, 'learning_rate': 1.763157894736842e-05, 'epoch': 67.5}\n",
      "{'loss': 0.1069, 'learning_rate': 1.736842105263158e-05, 'epoch': 68.0}\n",
      "{'loss': 0.1494, 'learning_rate': 1.7105263157894737e-05, 'epoch': 68.5}\n",
      "{'loss': 0.0937, 'learning_rate': 1.6842105263157896e-05, 'epoch': 69.0}\n",
      "{'loss': 0.0813, 'learning_rate': 1.6578947368421053e-05, 'epoch': 69.5}\n",
      "{'loss': 0.2171, 'learning_rate': 1.6315789473684213e-05, 'epoch': 70.0}\n",
      "{'loss': 0.1819, 'learning_rate': 1.605263157894737e-05, 'epoch': 70.5}\n",
      "{'loss': 0.0488, 'learning_rate': 1.5789473684210526e-05, 'epoch': 71.0}\n",
      "{'loss': 0.1682, 'learning_rate': 1.5526315789473686e-05, 'epoch': 71.5}\n",
      "{'loss': 0.0686, 'learning_rate': 1.5263157894736842e-05, 'epoch': 72.0}\n",
      "{'loss': 0.1915, 'learning_rate': 1.5e-05, 'epoch': 72.5}\n",
      "{'loss': 0.0687, 'learning_rate': 1.4736842105263157e-05, 'epoch': 73.0}\n",
      "{'loss': 0.1087, 'learning_rate': 1.4473684210526317e-05, 'epoch': 73.5}\n",
      "{'loss': 0.1756, 'learning_rate': 1.4210526315789475e-05, 'epoch': 74.0}\n",
      "{'loss': 0.1819, 'learning_rate': 1.3947368421052631e-05, 'epoch': 74.5}\n",
      "{'loss': 0.0428, 'learning_rate': 1.3684210526315791e-05, 'epoch': 75.0}\n",
      "{'loss': 0.1349, 'learning_rate': 1.3421052631578948e-05, 'epoch': 75.5}\n",
      "{'loss': 0.1343, 'learning_rate': 1.3157894736842106e-05, 'epoch': 76.0}\n",
      "{'loss': 0.1226, 'learning_rate': 1.2894736842105264e-05, 'epoch': 76.5}\n",
      "{'loss': 0.1447, 'learning_rate': 1.2631578947368422e-05, 'epoch': 77.0}\n",
      "{'loss': 0.1434, 'learning_rate': 1.2368421052631579e-05, 'epoch': 77.5}\n",
      "{'loss': 0.1265, 'learning_rate': 1.2105263157894737e-05, 'epoch': 78.0}\n",
      "{'loss': 0.1846, 'learning_rate': 1.1842105263157895e-05, 'epoch': 78.5}\n",
      "{'loss': 0.1801, 'learning_rate': 1.1578947368421053e-05, 'epoch': 79.0}\n",
      "{'loss': 0.1066, 'learning_rate': 1.1315789473684212e-05, 'epoch': 79.5}\n",
      "{'loss': 0.155, 'learning_rate': 1.1052631578947368e-05, 'epoch': 80.0}\n",
      "{'loss': 0.1688, 'learning_rate': 1.0789473684210526e-05, 'epoch': 80.5}\n",
      "{'loss': 0.0416, 'learning_rate': 1.0526315789473684e-05, 'epoch': 81.0}\n",
      "{'loss': 0.0824, 'learning_rate': 1.0263157894736843e-05, 'epoch': 81.5}\n",
      "{'loss': 0.1968, 'learning_rate': 1e-05, 'epoch': 82.0}\n",
      "{'loss': 0.1591, 'learning_rate': 9.736842105263157e-06, 'epoch': 82.5}\n",
      "{'loss': 0.0848, 'learning_rate': 9.473684210526317e-06, 'epoch': 83.0}\n",
      "{'loss': 0.1342, 'learning_rate': 9.210526315789474e-06, 'epoch': 83.5}\n",
      "{'loss': 0.1052, 'learning_rate': 8.947368421052632e-06, 'epoch': 84.0}\n",
      "{'loss': 0.1992, 'learning_rate': 8.68421052631579e-06, 'epoch': 84.5}\n",
      "{'loss': 0.0616, 'learning_rate': 8.421052631578948e-06, 'epoch': 85.0}\n",
      "{'loss': 0.1146, 'learning_rate': 8.157894736842106e-06, 'epoch': 85.5}\n",
      "{'loss': 0.1173, 'learning_rate': 7.894736842105263e-06, 'epoch': 86.0}\n",
      "{'loss': 0.1606, 'learning_rate': 7.631578947368421e-06, 'epoch': 86.5}\n",
      "{'loss': 0.0541, 'learning_rate': 7.3684210526315784e-06, 'epoch': 87.0}\n",
      "{'loss': 0.0856, 'learning_rate': 7.1052631578947375e-06, 'epoch': 87.5}\n",
      "{'loss': 0.1781, 'learning_rate': 6.842105263157896e-06, 'epoch': 88.0}\n",
      "{'loss': 0.1451, 'learning_rate': 6.578947368421053e-06, 'epoch': 88.5}\n",
      "{'loss': 0.1001, 'learning_rate': 6.315789473684211e-06, 'epoch': 89.0}\n",
      "{'loss': 0.0761, 'learning_rate': 6.0526315789473685e-06, 'epoch': 89.5}\n",
      "{'loss': 0.187, 'learning_rate': 5.789473684210527e-06, 'epoch': 90.0}\n",
      "{'loss': 0.1082, 'learning_rate': 5.526315789473684e-06, 'epoch': 90.5}\n",
      "{'loss': 0.1508, 'learning_rate': 5.263157894736842e-06, 'epoch': 91.0}\n",
      "{'loss': 0.1569, 'learning_rate': 5e-06, 'epoch': 91.5}\n",
      "{'loss': 0.0741, 'learning_rate': 4.736842105263159e-06, 'epoch': 92.0}\n",
      "{'loss': 0.1509, 'learning_rate': 4.473684210526316e-06, 'epoch': 92.5}\n",
      "{'loss': 0.0679, 'learning_rate': 4.210526315789474e-06, 'epoch': 93.0}\n",
      "{'loss': 0.1193, 'learning_rate': 3.9473684210526315e-06, 'epoch': 93.5}\n",
      "{'loss': 0.1511, 'learning_rate': 3.6842105263157892e-06, 'epoch': 94.0}\n",
      "{'loss': 0.0823, 'learning_rate': 3.421052631578948e-06, 'epoch': 94.5}\n",
      "{'loss': 0.1569, 'learning_rate': 3.1578947368421056e-06, 'epoch': 95.0}\n",
      "{'loss': 0.0534, 'learning_rate': 2.8947368421052634e-06, 'epoch': 95.5}\n",
      "{'loss': 0.2099, 'learning_rate': 2.631578947368421e-06, 'epoch': 96.0}\n",
      "{'loss': 0.1565, 'learning_rate': 2.3684210526315793e-06, 'epoch': 96.5}\n",
      "{'loss': 0.0562, 'learning_rate': 2.105263157894737e-06, 'epoch': 97.0}\n",
      "{'loss': 0.1532, 'learning_rate': 1.8421052631578946e-06, 'epoch': 97.5}\n",
      "{'loss': 0.0676, 'learning_rate': 1.5789473684210528e-06, 'epoch': 98.0}\n",
      "{'loss': 0.1386, 'learning_rate': 1.3157894736842106e-06, 'epoch': 98.5}\n",
      "{'loss': 0.0782, 'learning_rate': 1.0526315789473685e-06, 'epoch': 99.0}\n",
      "{'loss': 0.0972, 'learning_rate': 7.894736842105264e-07, 'epoch': 99.5}\n",
      "{'loss': 0.1648, 'learning_rate': 5.263157894736843e-07, 'epoch': 100.0}\n",
      "{'train_runtime': 967.3008, 'train_samples_per_second': 5.893, 'train_steps_per_second': 0.207, 'train_loss': 0.22637936547398568, 'epoch': 100.0}\n",
      "Fitting model using fold 3 as out of fold data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at kiddothe2b/longformer-mini-1024 were not used when initializing LongformerForSequenceClassification: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.bias', 'longformer.embeddings.position_ids']\n",
      "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at kiddothe2b/longformer-mini-1024 and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/61 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6865, 'learning_rate': 5e-06, 'epoch': 0.5}\n",
      "{'loss': 0.7122, 'learning_rate': 1e-05, 'epoch': 1.0}\n",
      "{'loss': 0.7037, 'learning_rate': 1.5e-05, 'epoch': 1.5}\n",
      "{'loss': 0.7075, 'learning_rate': 2e-05, 'epoch': 2.0}\n",
      "{'loss': 0.6808, 'learning_rate': 2.5e-05, 'epoch': 2.5}\n",
      "{'loss': 0.6838, 'learning_rate': 3e-05, 'epoch': 3.0}\n",
      "{'loss': 0.6836, 'learning_rate': 3.5e-05, 'epoch': 3.5}\n",
      "{'loss': 0.6898, 'learning_rate': 4e-05, 'epoch': 4.0}\n",
      "{'loss': 0.6586, 'learning_rate': 4.5e-05, 'epoch': 4.5}\n",
      "{'loss': 0.6852, 'learning_rate': 5e-05, 'epoch': 5.0}\n",
      "{'loss': 0.6241, 'learning_rate': 4.973684210526316e-05, 'epoch': 5.5}\n",
      "{'loss': 0.6966, 'learning_rate': 4.9473684210526315e-05, 'epoch': 6.0}\n",
      "{'loss': 0.6518, 'learning_rate': 4.921052631578947e-05, 'epoch': 6.5}\n",
      "{'loss': 0.6486, 'learning_rate': 4.8947368421052635e-05, 'epoch': 7.0}\n",
      "{'loss': 0.6592, 'learning_rate': 4.868421052631579e-05, 'epoch': 7.5}\n",
      "{'loss': 0.6163, 'learning_rate': 4.842105263157895e-05, 'epoch': 8.0}\n",
      "{'loss': 0.6073, 'learning_rate': 4.8157894736842105e-05, 'epoch': 8.5}\n",
      "{'loss': 0.6308, 'learning_rate': 4.789473684210526e-05, 'epoch': 9.0}\n",
      "{'loss': 0.6382, 'learning_rate': 4.7631578947368424e-05, 'epoch': 9.5}\n",
      "{'loss': 0.5914, 'learning_rate': 4.736842105263158e-05, 'epoch': 10.0}\n",
      "{'loss': 0.6185, 'learning_rate': 4.7105263157894744e-05, 'epoch': 10.5}\n",
      "{'loss': 0.5739, 'learning_rate': 4.68421052631579e-05, 'epoch': 11.0}\n",
      "{'loss': 0.6133, 'learning_rate': 4.657894736842106e-05, 'epoch': 11.5}\n",
      "{'loss': 0.5446, 'learning_rate': 4.6315789473684214e-05, 'epoch': 12.0}\n",
      "{'loss': 0.579, 'learning_rate': 4.605263157894737e-05, 'epoch': 12.5}\n",
      "{'loss': 0.5459, 'learning_rate': 4.5789473684210527e-05, 'epoch': 13.0}\n",
      "{'loss': 0.4904, 'learning_rate': 4.552631578947369e-05, 'epoch': 13.5}\n",
      "{'loss': 0.573, 'learning_rate': 4.5263157894736846e-05, 'epoch': 14.0}\n",
      "{'loss': 0.5129, 'learning_rate': 4.5e-05, 'epoch': 14.5}\n",
      "{'loss': 0.477, 'learning_rate': 4.473684210526316e-05, 'epoch': 15.0}\n",
      "{'loss': 0.4583, 'learning_rate': 4.4473684210526316e-05, 'epoch': 15.5}\n",
      "{'loss': 0.4944, 'learning_rate': 4.421052631578947e-05, 'epoch': 16.0}\n",
      "{'loss': 0.376, 'learning_rate': 4.394736842105263e-05, 'epoch': 16.5}\n",
      "{'loss': 0.4823, 'learning_rate': 4.368421052631579e-05, 'epoch': 17.0}\n",
      "{'loss': 0.4154, 'learning_rate': 4.342105263157895e-05, 'epoch': 17.5}\n",
      "{'loss': 0.3788, 'learning_rate': 4.3157894736842105e-05, 'epoch': 18.0}\n",
      "{'loss': 0.3561, 'learning_rate': 4.289473684210527e-05, 'epoch': 18.5}\n",
      "{'loss': 0.3841, 'learning_rate': 4.2631578947368425e-05, 'epoch': 19.0}\n",
      "{'loss': 0.2937, 'learning_rate': 4.236842105263158e-05, 'epoch': 19.5}\n",
      "{'loss': 0.356, 'learning_rate': 4.210526315789474e-05, 'epoch': 20.0}\n",
      "{'loss': 0.3064, 'learning_rate': 4.18421052631579e-05, 'epoch': 20.5}\n",
      "{'loss': 0.2794, 'learning_rate': 4.157894736842106e-05, 'epoch': 21.0}\n",
      "{'loss': 0.3069, 'learning_rate': 4.1315789473684214e-05, 'epoch': 21.5}\n",
      "{'loss': 0.2077, 'learning_rate': 4.105263157894737e-05, 'epoch': 22.0}\n",
      "{'loss': 0.2489, 'learning_rate': 4.078947368421053e-05, 'epoch': 22.5}\n",
      "{'loss': 0.2534, 'learning_rate': 4.0526315789473684e-05, 'epoch': 23.0}\n",
      "{'loss': 0.2824, 'learning_rate': 4.026315789473684e-05, 'epoch': 23.5}\n",
      "{'loss': 0.1612, 'learning_rate': 4e-05, 'epoch': 24.0}\n",
      "{'loss': 0.2047, 'learning_rate': 3.973684210526316e-05, 'epoch': 24.5}\n",
      "{'loss': 0.2042, 'learning_rate': 3.9473684210526316e-05, 'epoch': 25.0}\n",
      "{'loss': 0.1323, 'learning_rate': 3.921052631578947e-05, 'epoch': 25.5}\n",
      "{'loss': 0.2638, 'learning_rate': 3.894736842105263e-05, 'epoch': 26.0}\n",
      "{'loss': 0.2315, 'learning_rate': 3.868421052631579e-05, 'epoch': 26.5}\n",
      "{'loss': 0.1074, 'learning_rate': 3.842105263157895e-05, 'epoch': 27.0}\n",
      "{'loss': 0.2255, 'learning_rate': 3.815789473684211e-05, 'epoch': 27.5}\n",
      "{'loss': 0.0981, 'learning_rate': 3.789473684210527e-05, 'epoch': 28.0}\n",
      "{'loss': 0.1584, 'learning_rate': 3.7631578947368425e-05, 'epoch': 28.5}\n",
      "{'loss': 0.1651, 'learning_rate': 3.736842105263158e-05, 'epoch': 29.0}\n",
      "{'loss': 0.1533, 'learning_rate': 3.710526315789474e-05, 'epoch': 29.5}\n",
      "{'loss': 0.1567, 'learning_rate': 3.6842105263157895e-05, 'epoch': 30.0}\n",
      "{'loss': 0.0792, 'learning_rate': 3.657894736842106e-05, 'epoch': 30.5}\n",
      "{'loss': 0.2095, 'learning_rate': 3.6315789473684214e-05, 'epoch': 31.0}\n",
      "{'loss': 0.129, 'learning_rate': 3.605263157894737e-05, 'epoch': 31.5}\n",
      "{'loss': 0.1476, 'learning_rate': 3.578947368421053e-05, 'epoch': 32.0}\n",
      "{'loss': 0.1381, 'learning_rate': 3.5526315789473684e-05, 'epoch': 32.5}\n",
      "{'loss': 0.1483, 'learning_rate': 3.526315789473684e-05, 'epoch': 33.0}\n",
      "{'loss': 0.1436, 'learning_rate': 3.5e-05, 'epoch': 33.5}\n",
      "{'loss': 0.1399, 'learning_rate': 3.473684210526316e-05, 'epoch': 34.0}\n",
      "{'loss': 0.1372, 'learning_rate': 3.447368421052632e-05, 'epoch': 34.5}\n",
      "{'loss': 0.1218, 'learning_rate': 3.421052631578947e-05, 'epoch': 35.0}\n",
      "{'loss': 0.1867, 'learning_rate': 3.3947368421052636e-05, 'epoch': 35.5}\n",
      "{'loss': 0.0633, 'learning_rate': 3.368421052631579e-05, 'epoch': 36.0}\n",
      "{'loss': 0.12, 'learning_rate': 3.342105263157895e-05, 'epoch': 36.5}\n",
      "{'loss': 0.1191, 'learning_rate': 3.3157894736842106e-05, 'epoch': 37.0}\n",
      "{'loss': 0.1081, 'learning_rate': 3.289473684210527e-05, 'epoch': 37.5}\n",
      "{'loss': 0.1375, 'learning_rate': 3.2631578947368426e-05, 'epoch': 38.0}\n",
      "{'loss': 0.1714, 'learning_rate': 3.236842105263158e-05, 'epoch': 38.5}\n",
      "{'loss': 0.0535, 'learning_rate': 3.210526315789474e-05, 'epoch': 39.0}\n",
      "{'loss': 0.11, 'learning_rate': 3.1842105263157895e-05, 'epoch': 39.5}\n",
      "{'loss': 0.1248, 'learning_rate': 3.157894736842105e-05, 'epoch': 40.0}\n",
      "{'loss': 0.1634, 'learning_rate': 3.131578947368421e-05, 'epoch': 40.5}\n",
      "{'loss': 0.074, 'learning_rate': 3.105263157894737e-05, 'epoch': 41.0}\n",
      "{'loss': 0.1237, 'learning_rate': 3.078947368421053e-05, 'epoch': 41.5}\n",
      "{'loss': 0.1151, 'learning_rate': 3.0526315789473684e-05, 'epoch': 42.0}\n",
      "{'loss': 0.0636, 'learning_rate': 3.0263157894736844e-05, 'epoch': 42.5}\n",
      "{'loss': 0.1589, 'learning_rate': 3e-05, 'epoch': 43.0}\n",
      "{'loss': 0.1213, 'learning_rate': 2.9736842105263157e-05, 'epoch': 43.5}\n",
      "{'loss': 0.1211, 'learning_rate': 2.9473684210526314e-05, 'epoch': 44.0}\n",
      "{'loss': 0.0505, 'learning_rate': 2.9210526315789477e-05, 'epoch': 44.5}\n",
      "{'loss': 0.1862, 'learning_rate': 2.8947368421052634e-05, 'epoch': 45.0}\n",
      "{'loss': 0.1654, 'learning_rate': 2.868421052631579e-05, 'epoch': 45.5}\n",
      "{'loss': 0.0527, 'learning_rate': 2.842105263157895e-05, 'epoch': 46.0}\n",
      "{'loss': 0.1027, 'learning_rate': 2.8157894736842106e-05, 'epoch': 46.5}\n",
      "{'loss': 0.1345, 'learning_rate': 2.7894736842105263e-05, 'epoch': 47.0}\n",
      "{'loss': 0.0985, 'learning_rate': 2.7631578947368426e-05, 'epoch': 47.5}\n",
      "{'loss': 0.1131, 'learning_rate': 2.7368421052631583e-05, 'epoch': 48.0}\n",
      "{'loss': 0.1147, 'learning_rate': 2.710526315789474e-05, 'epoch': 48.5}\n",
      "{'loss': 0.1195, 'learning_rate': 2.6842105263157896e-05, 'epoch': 49.0}\n",
      "{'loss': 0.1012, 'learning_rate': 2.6578947368421052e-05, 'epoch': 49.5}\n",
      "{'loss': 0.1121, 'learning_rate': 2.6315789473684212e-05, 'epoch': 50.0}\n",
      "{'loss': 0.1632, 'learning_rate': 2.605263157894737e-05, 'epoch': 50.5}\n",
      "{'loss': 0.0428, 'learning_rate': 2.578947368421053e-05, 'epoch': 51.0}\n",
      "{'loss': 0.0411, 'learning_rate': 2.5526315789473688e-05, 'epoch': 51.5}\n",
      "{'loss': 0.1937, 'learning_rate': 2.5263157894736845e-05, 'epoch': 52.0}\n",
      "{'loss': 0.0361, 'learning_rate': 2.5e-05, 'epoch': 52.5}\n",
      "{'loss': 0.1912, 'learning_rate': 2.4736842105263158e-05, 'epoch': 53.0}\n",
      "{'loss': 0.1544, 'learning_rate': 2.4473684210526318e-05, 'epoch': 53.5}\n",
      "{'loss': 0.0425, 'learning_rate': 2.4210526315789474e-05, 'epoch': 54.0}\n",
      "{'loss': 0.149, 'learning_rate': 2.394736842105263e-05, 'epoch': 54.5}\n",
      "{'loss': 0.0584, 'learning_rate': 2.368421052631579e-05, 'epoch': 55.0}\n",
      "{'loss': 0.1552, 'learning_rate': 2.342105263157895e-05, 'epoch': 55.5}\n",
      "{'loss': 0.0568, 'learning_rate': 2.3157894736842107e-05, 'epoch': 56.0}\n",
      "{'loss': 0.0423, 'learning_rate': 2.2894736842105263e-05, 'epoch': 56.5}\n",
      "{'loss': 0.1457, 'learning_rate': 2.2631578947368423e-05, 'epoch': 57.0}\n",
      "{'loss': 0.1053, 'learning_rate': 2.236842105263158e-05, 'epoch': 57.5}\n",
      "{'loss': 0.1166, 'learning_rate': 2.2105263157894736e-05, 'epoch': 58.0}\n",
      "{'loss': 0.1216, 'learning_rate': 2.1842105263157896e-05, 'epoch': 58.5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0876, 'learning_rate': 2.1578947368421053e-05, 'epoch': 59.0}\n",
      "{'loss': 0.0455, 'learning_rate': 2.1315789473684212e-05, 'epoch': 59.5}\n",
      "{'loss': 0.1406, 'learning_rate': 2.105263157894737e-05, 'epoch': 60.0}\n",
      "{'loss': 0.1181, 'learning_rate': 2.078947368421053e-05, 'epoch': 60.5}\n",
      "{'loss': 0.0962, 'learning_rate': 2.0526315789473685e-05, 'epoch': 61.0}\n",
      "{'loss': 0.1006, 'learning_rate': 2.0263157894736842e-05, 'epoch': 61.5}\n",
      "{'loss': 0.0943, 'learning_rate': 2e-05, 'epoch': 62.0}\n",
      "{'loss': 0.1631, 'learning_rate': 1.9736842105263158e-05, 'epoch': 62.5}\n",
      "{'loss': 0.0442, 'learning_rate': 1.9473684210526315e-05, 'epoch': 63.0}\n",
      "{'loss': 0.0401, 'learning_rate': 1.9210526315789474e-05, 'epoch': 63.5}\n",
      "{'loss': 0.1772, 'learning_rate': 1.8947368421052634e-05, 'epoch': 64.0}\n",
      "{'loss': 0.0885, 'learning_rate': 1.868421052631579e-05, 'epoch': 64.5}\n",
      "{'loss': 0.1119, 'learning_rate': 1.8421052631578947e-05, 'epoch': 65.0}\n",
      "{'loss': 0.0429, 'learning_rate': 1.8157894736842107e-05, 'epoch': 65.5}\n",
      "{'loss': 0.1701, 'learning_rate': 1.7894736842105264e-05, 'epoch': 66.0}\n",
      "{'loss': 0.0959, 'learning_rate': 1.763157894736842e-05, 'epoch': 66.5}\n",
      "{'loss': 0.0983, 'learning_rate': 1.736842105263158e-05, 'epoch': 67.0}\n",
      "{'loss': 0.1406, 'learning_rate': 1.7105263157894737e-05, 'epoch': 67.5}\n",
      "{'loss': 0.0346, 'learning_rate': 1.6842105263157896e-05, 'epoch': 68.0}\n",
      "{'loss': 0.0838, 'learning_rate': 1.6578947368421053e-05, 'epoch': 68.5}\n",
      "{'loss': 0.092, 'learning_rate': 1.6315789473684213e-05, 'epoch': 69.0}\n",
      "{'loss': 0.1003, 'learning_rate': 1.605263157894737e-05, 'epoch': 69.5}\n",
      "{'loss': 0.0972, 'learning_rate': 1.5789473684210526e-05, 'epoch': 70.0}\n",
      "{'loss': 0.0828, 'learning_rate': 1.5526315789473686e-05, 'epoch': 70.5}\n",
      "{'loss': 0.1036, 'learning_rate': 1.5263157894736842e-05, 'epoch': 71.0}\n",
      "{'loss': 0.0789, 'learning_rate': 1.5e-05, 'epoch': 71.5}\n",
      "{'loss': 0.1069, 'learning_rate': 1.4736842105263157e-05, 'epoch': 72.0}\n",
      "{'loss': 0.076, 'learning_rate': 1.4473684210526317e-05, 'epoch': 72.5}\n",
      "{'loss': 0.1197, 'learning_rate': 1.4210526315789475e-05, 'epoch': 73.0}\n",
      "{'loss': 0.0798, 'learning_rate': 1.3947368421052631e-05, 'epoch': 73.5}\n",
      "{'loss': 0.1181, 'learning_rate': 1.3684210526315791e-05, 'epoch': 74.0}\n",
      "{'loss': 0.1026, 'learning_rate': 1.3421052631578948e-05, 'epoch': 74.5}\n",
      "{'loss': 0.0943, 'learning_rate': 1.3157894736842106e-05, 'epoch': 75.0}\n",
      "{'loss': 0.0954, 'learning_rate': 1.2894736842105264e-05, 'epoch': 75.5}\n",
      "{'loss': 0.1014, 'learning_rate': 1.2631578947368422e-05, 'epoch': 76.0}\n",
      "{'loss': 0.1719, 'learning_rate': 1.2368421052631579e-05, 'epoch': 76.5}\n",
      "{'loss': 0.0361, 'learning_rate': 1.2105263157894737e-05, 'epoch': 77.0}\n",
      "{'loss': 0.1083, 'learning_rate': 1.1842105263157895e-05, 'epoch': 77.5}\n",
      "{'loss': 0.1009, 'learning_rate': 1.1578947368421053e-05, 'epoch': 78.0}\n",
      "{'loss': 0.045, 'learning_rate': 1.1315789473684212e-05, 'epoch': 78.5}\n",
      "{'loss': 0.177, 'learning_rate': 1.1052631578947368e-05, 'epoch': 79.0}\n",
      "{'loss': 0.1614, 'learning_rate': 1.0789473684210526e-05, 'epoch': 79.5}\n",
      "{'loss': 0.0443, 'learning_rate': 1.0526315789473684e-05, 'epoch': 80.0}\n",
      "{'loss': 0.1413, 'learning_rate': 1.0263157894736843e-05, 'epoch': 80.5}\n",
      "{'loss': 0.0299, 'learning_rate': 1e-05, 'epoch': 81.0}\n",
      "{'loss': 0.0391, 'learning_rate': 9.736842105263157e-06, 'epoch': 81.5}\n",
      "{'loss': 0.1594, 'learning_rate': 9.473684210526317e-06, 'epoch': 82.0}\n",
      "{'loss': 0.0443, 'learning_rate': 9.210526315789474e-06, 'epoch': 82.5}\n",
      "{'loss': 0.1599, 'learning_rate': 8.947368421052632e-06, 'epoch': 83.0}\n",
      "{'loss': 0.0227, 'learning_rate': 8.68421052631579e-06, 'epoch': 83.5}\n",
      "{'loss': 0.2121, 'learning_rate': 8.421052631578948e-06, 'epoch': 84.0}\n",
      "{'loss': 0.1115, 'learning_rate': 8.157894736842106e-06, 'epoch': 84.5}\n",
      "{'loss': 0.0866, 'learning_rate': 7.894736842105263e-06, 'epoch': 85.0}\n",
      "{'loss': 0.0917, 'learning_rate': 7.631578947368421e-06, 'epoch': 85.5}\n",
      "{'loss': 0.0939, 'learning_rate': 7.3684210526315784e-06, 'epoch': 86.0}\n",
      "{'loss': 0.1486, 'learning_rate': 7.1052631578947375e-06, 'epoch': 86.5}\n",
      "{'loss': 0.0407, 'learning_rate': 6.842105263157896e-06, 'epoch': 87.0}\n",
      "{'loss': 0.1507, 'learning_rate': 6.578947368421053e-06, 'epoch': 87.5}\n",
      "{'loss': 0.05, 'learning_rate': 6.315789473684211e-06, 'epoch': 88.0}\n",
      "{'loss': 0.1457, 'learning_rate': 6.0526315789473685e-06, 'epoch': 88.5}\n",
      "{'loss': 0.0481, 'learning_rate': 5.789473684210527e-06, 'epoch': 89.0}\n",
      "{'loss': 0.1749, 'learning_rate': 5.526315789473684e-06, 'epoch': 89.5}\n",
      "{'loss': 0.0441, 'learning_rate': 5.263157894736842e-06, 'epoch': 90.0}\n",
      "{'loss': 0.17, 'learning_rate': 5e-06, 'epoch': 90.5}\n",
      "{'loss': 0.0213, 'learning_rate': 4.736842105263159e-06, 'epoch': 91.0}\n",
      "{'loss': 0.0327, 'learning_rate': 4.473684210526316e-06, 'epoch': 91.5}\n",
      "{'loss': 0.1623, 'learning_rate': 4.210526315789474e-06, 'epoch': 92.0}\n",
      "{'loss': 0.0766, 'learning_rate': 3.9473684210526315e-06, 'epoch': 92.5}\n",
      "{'loss': 0.1112, 'learning_rate': 3.6842105263157892e-06, 'epoch': 93.0}\n",
      "{'loss': 0.0916, 'learning_rate': 3.421052631578948e-06, 'epoch': 93.5}\n",
      "{'loss': 0.0895, 'learning_rate': 3.1578947368421056e-06, 'epoch': 94.0}\n",
      "{'loss': 0.0848, 'learning_rate': 2.8947368421052634e-06, 'epoch': 94.5}\n",
      "{'loss': 0.0964, 'learning_rate': 2.631578947368421e-06, 'epoch': 95.0}\n",
      "{'loss': 0.1367, 'learning_rate': 2.3684210526315793e-06, 'epoch': 95.5}\n",
      "{'loss': 0.0417, 'learning_rate': 2.105263157894737e-06, 'epoch': 96.0}\n",
      "{'loss': 0.085, 'learning_rate': 1.8421052631578946e-06, 'epoch': 96.5}\n",
      "{'loss': 0.1173, 'learning_rate': 1.5789473684210528e-06, 'epoch': 97.0}\n",
      "{'loss': 0.0786, 'learning_rate': 1.3157894736842106e-06, 'epoch': 97.5}\n",
      "{'loss': 0.0956, 'learning_rate': 1.0526315789473685e-06, 'epoch': 98.0}\n",
      "{'loss': 0.1337, 'learning_rate': 7.894736842105264e-07, 'epoch': 98.5}\n",
      "{'loss': 0.0525, 'learning_rate': 5.263157894736843e-07, 'epoch': 99.0}\n",
      "{'loss': 0.0956, 'learning_rate': 2.6315789473684213e-07, 'epoch': 99.5}\n",
      "{'loss': 0.0844, 'learning_rate': 0.0, 'epoch': 100.0}\n",
      "{'train_runtime': 1051.5664, 'train_samples_per_second': 5.801, 'train_steps_per_second': 0.19, 'train_loss': 0.20872399965301155, 'epoch': 100.0}\n",
      "Fitting model using fold 4 as out of fold data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at kiddothe2b/longformer-mini-1024 were not used when initializing LongformerForSequenceClassification: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.bias', 'longformer.embeddings.position_ids']\n",
      "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at kiddothe2b/longformer-mini-1024 and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/59 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6856, 'learning_rate': 5e-06, 'epoch': 0.5}\n",
      "{'loss': 0.6948, 'learning_rate': 1e-05, 'epoch': 1.0}\n",
      "{'loss': 0.6737, 'learning_rate': 1.5e-05, 'epoch': 1.5}\n",
      "{'loss': 0.7271, 'learning_rate': 2e-05, 'epoch': 2.0}\n",
      "{'loss': 0.6925, 'learning_rate': 2.5e-05, 'epoch': 2.5}\n",
      "{'loss': 0.6949, 'learning_rate': 3e-05, 'epoch': 3.0}\n",
      "{'loss': 0.6806, 'learning_rate': 3.5e-05, 'epoch': 3.5}\n",
      "{'loss': 0.6957, 'learning_rate': 4e-05, 'epoch': 4.0}\n",
      "{'loss': 0.6887, 'learning_rate': 4.5e-05, 'epoch': 4.5}\n",
      "{'loss': 0.6745, 'learning_rate': 5e-05, 'epoch': 5.0}\n",
      "{'loss': 0.6789, 'learning_rate': 4.973684210526316e-05, 'epoch': 5.5}\n",
      "{'loss': 0.6635, 'learning_rate': 4.9473684210526315e-05, 'epoch': 6.0}\n",
      "{'loss': 0.6836, 'learning_rate': 4.921052631578947e-05, 'epoch': 6.5}\n",
      "{'loss': 0.6308, 'learning_rate': 4.8947368421052635e-05, 'epoch': 7.0}\n",
      "{'loss': 0.6288, 'learning_rate': 4.868421052631579e-05, 'epoch': 7.5}\n",
      "{'loss': 0.6618, 'learning_rate': 4.842105263157895e-05, 'epoch': 8.0}\n",
      "{'loss': 0.6325, 'learning_rate': 4.8157894736842105e-05, 'epoch': 8.5}\n",
      "{'loss': 0.6454, 'learning_rate': 4.789473684210526e-05, 'epoch': 9.0}\n",
      "{'loss': 0.6256, 'learning_rate': 4.7631578947368424e-05, 'epoch': 9.5}\n",
      "{'loss': 0.633, 'learning_rate': 4.736842105263158e-05, 'epoch': 10.0}\n",
      "{'loss': 0.5895, 'learning_rate': 4.7105263157894744e-05, 'epoch': 10.5}\n",
      "{'loss': 0.6424, 'learning_rate': 4.68421052631579e-05, 'epoch': 11.0}\n",
      "{'loss': 0.581, 'learning_rate': 4.657894736842106e-05, 'epoch': 11.5}\n",
      "{'loss': 0.6122, 'learning_rate': 4.6315789473684214e-05, 'epoch': 12.0}\n",
      "{'loss': 0.549, 'learning_rate': 4.605263157894737e-05, 'epoch': 12.5}\n",
      "{'loss': 0.5833, 'learning_rate': 4.5789473684210527e-05, 'epoch': 13.0}\n",
      "{'loss': 0.5215, 'learning_rate': 4.552631578947369e-05, 'epoch': 13.5}\n",
      "{'loss': 0.5461, 'learning_rate': 4.5263157894736846e-05, 'epoch': 14.0}\n",
      "{'loss': 0.4368, 'learning_rate': 4.5e-05, 'epoch': 14.5}\n",
      "{'loss': 0.5925, 'learning_rate': 4.473684210526316e-05, 'epoch': 15.0}\n",
      "{'loss': 0.4817, 'learning_rate': 4.4473684210526316e-05, 'epoch': 15.5}\n",
      "{'loss': 0.438, 'learning_rate': 4.421052631578947e-05, 'epoch': 16.0}\n",
      "{'loss': 0.4834, 'learning_rate': 4.394736842105263e-05, 'epoch': 16.5}\n",
      "{'loss': 0.3845, 'learning_rate': 4.368421052631579e-05, 'epoch': 17.0}\n",
      "{'loss': 0.3683, 'learning_rate': 4.342105263157895e-05, 'epoch': 17.5}\n",
      "{'loss': 0.4401, 'learning_rate': 4.3157894736842105e-05, 'epoch': 18.0}\n",
      "{'loss': 0.3727, 'learning_rate': 4.289473684210527e-05, 'epoch': 18.5}\n",
      "{'loss': 0.3715, 'learning_rate': 4.2631578947368425e-05, 'epoch': 19.0}\n",
      "{'loss': 0.3622, 'learning_rate': 4.236842105263158e-05, 'epoch': 19.5}\n",
      "{'loss': 0.3311, 'learning_rate': 4.210526315789474e-05, 'epoch': 20.0}\n",
      "{'loss': 0.3059, 'learning_rate': 4.18421052631579e-05, 'epoch': 20.5}\n",
      "{'loss': 0.3304, 'learning_rate': 4.157894736842106e-05, 'epoch': 21.0}\n",
      "{'loss': 0.2889, 'learning_rate': 4.1315789473684214e-05, 'epoch': 21.5}\n",
      "{'loss': 0.302, 'learning_rate': 4.105263157894737e-05, 'epoch': 22.0}\n",
      "{'loss': 0.2299, 'learning_rate': 4.078947368421053e-05, 'epoch': 22.5}\n",
      "{'loss': 0.3528, 'learning_rate': 4.0526315789473684e-05, 'epoch': 23.0}\n",
      "{'loss': 0.3051, 'learning_rate': 4.026315789473684e-05, 'epoch': 23.5}\n",
      "{'loss': 0.2434, 'learning_rate': 4e-05, 'epoch': 24.0}\n",
      "{'loss': 0.2442, 'learning_rate': 3.973684210526316e-05, 'epoch': 24.5}\n",
      "{'loss': 0.2573, 'learning_rate': 3.9473684210526316e-05, 'epoch': 25.0}\n",
      "{'loss': 0.2246, 'learning_rate': 3.921052631578947e-05, 'epoch': 25.5}\n",
      "{'loss': 0.2613, 'learning_rate': 3.894736842105263e-05, 'epoch': 26.0}\n",
      "{'loss': 0.2034, 'learning_rate': 3.868421052631579e-05, 'epoch': 26.5}\n",
      "{'loss': 0.2676, 'learning_rate': 3.842105263157895e-05, 'epoch': 27.0}\n",
      "{'loss': 0.2131, 'learning_rate': 3.815789473684211e-05, 'epoch': 27.5}\n",
      "{'loss': 0.2217, 'learning_rate': 3.789473684210527e-05, 'epoch': 28.0}\n",
      "{'loss': 0.1541, 'learning_rate': 3.7631578947368425e-05, 'epoch': 28.5}\n",
      "{'loss': 0.2832, 'learning_rate': 3.736842105263158e-05, 'epoch': 29.0}\n",
      "{'loss': 0.1682, 'learning_rate': 3.710526315789474e-05, 'epoch': 29.5}\n",
      "{'loss': 0.2521, 'learning_rate': 3.6842105263157895e-05, 'epoch': 30.0}\n",
      "{'loss': 0.2679, 'learning_rate': 3.657894736842106e-05, 'epoch': 30.5}\n",
      "{'loss': 0.1292, 'learning_rate': 3.6315789473684214e-05, 'epoch': 31.0}\n",
      "{'loss': 0.2334, 'learning_rate': 3.605263157894737e-05, 'epoch': 31.5}\n",
      "{'loss': 0.1971, 'learning_rate': 3.578947368421053e-05, 'epoch': 32.0}\n",
      "{'loss': 0.1819, 'learning_rate': 3.5526315789473684e-05, 'epoch': 32.5}\n",
      "{'loss': 0.2401, 'learning_rate': 3.526315789473684e-05, 'epoch': 33.0}\n",
      "{'loss': 0.2895, 'learning_rate': 3.5e-05, 'epoch': 33.5}\n",
      "{'loss': 0.0958, 'learning_rate': 3.473684210526316e-05, 'epoch': 34.0}\n",
      "{'loss': 0.2004, 'learning_rate': 3.447368421052632e-05, 'epoch': 34.5}\n",
      "{'loss': 0.1823, 'learning_rate': 3.421052631578947e-05, 'epoch': 35.0}\n",
      "{'loss': 0.1886, 'learning_rate': 3.3947368421052636e-05, 'epoch': 35.5}\n",
      "{'loss': 0.2206, 'learning_rate': 3.368421052631579e-05, 'epoch': 36.0}\n",
      "{'loss': 0.2865, 'learning_rate': 3.368421052631579e-05, 'epoch': 36.5}\n",
      "{'loss': 0.1002, 'learning_rate': 3.342105263157895e-05, 'epoch': 37.0}\n",
      "{'loss': 0.2319, 'learning_rate': 3.3157894736842106e-05, 'epoch': 37.5}\n",
      "{'loss': 0.1816, 'learning_rate': 3.289473684210527e-05, 'epoch': 38.0}\n",
      "{'loss': 0.2262, 'learning_rate': 3.2631578947368426e-05, 'epoch': 38.5}\n",
      "{'loss': 0.1526, 'learning_rate': 3.236842105263158e-05, 'epoch': 39.0}\n",
      "{'loss': 0.1967, 'learning_rate': 3.210526315789474e-05, 'epoch': 39.5}\n",
      "{'loss': 0.1627, 'learning_rate': 3.1842105263157895e-05, 'epoch': 40.0}\n",
      "{'loss': 0.1946, 'learning_rate': 3.157894736842105e-05, 'epoch': 40.5}\n",
      "{'loss': 0.1795, 'learning_rate': 3.131578947368421e-05, 'epoch': 41.0}\n",
      "{'loss': 0.0721, 'learning_rate': 3.105263157894737e-05, 'epoch': 41.5}\n",
      "{'loss': 0.3146, 'learning_rate': 3.078947368421053e-05, 'epoch': 42.0}\n",
      "{'loss': 0.1872, 'learning_rate': 3.078947368421053e-05, 'epoch': 42.5}\n",
      "{'loss': 0.2436, 'learning_rate': 3.0526315789473684e-05, 'epoch': 43.0}\n",
      "{'loss': 0.1522, 'learning_rate': 3.0263157894736844e-05, 'epoch': 43.5}\n",
      "{'loss': 0.19, 'learning_rate': 3e-05, 'epoch': 44.0}\n",
      "{'loss': 0.2089, 'learning_rate': 2.9736842105263157e-05, 'epoch': 44.5}\n",
      "{'loss': 0.1224, 'learning_rate': 2.9473684210526314e-05, 'epoch': 45.0}\n",
      "{'loss': 0.136, 'learning_rate': 2.9210526315789477e-05, 'epoch': 45.5}\n",
      "{'loss': 0.2198, 'learning_rate': 2.8947368421052634e-05, 'epoch': 46.0}\n",
      "{'loss': 0.2151, 'learning_rate': 2.868421052631579e-05, 'epoch': 46.5}\n",
      "{'loss': 0.1509, 'learning_rate': 2.842105263157895e-05, 'epoch': 47.0}\n",
      "{'loss': 0.1803, 'learning_rate': 2.8157894736842106e-05, 'epoch': 47.5}\n",
      "{'loss': 0.1854, 'learning_rate': 2.7894736842105263e-05, 'epoch': 48.0}\n",
      "{'loss': 0.158, 'learning_rate': 2.7631578947368426e-05, 'epoch': 48.5}\n",
      "{'loss': 0.213, 'learning_rate': 2.7368421052631583e-05, 'epoch': 49.0}\n",
      "{'loss': 0.2172, 'learning_rate': 2.710526315789474e-05, 'epoch': 49.5}\n",
      "{'loss': 0.1098, 'learning_rate': 2.6842105263157896e-05, 'epoch': 50.0}\n",
      "{'loss': 0.1532, 'learning_rate': 2.6578947368421052e-05, 'epoch': 50.5}\n",
      "{'loss': 0.1818, 'learning_rate': 2.6315789473684212e-05, 'epoch': 51.0}\n",
      "{'loss': 0.192, 'learning_rate': 2.605263157894737e-05, 'epoch': 51.5}\n",
      "{'loss': 0.1615, 'learning_rate': 2.578947368421053e-05, 'epoch': 52.0}\n",
      "{'loss': 0.195, 'learning_rate': 2.5526315789473688e-05, 'epoch': 52.5}\n",
      "{'loss': 0.1421, 'learning_rate': 2.5263157894736845e-05, 'epoch': 53.0}\n",
      "{'loss': 0.2669, 'learning_rate': 2.5e-05, 'epoch': 53.5}\n",
      "{'loss': 0.1697, 'learning_rate': 2.4736842105263158e-05, 'epoch': 54.0}\n",
      "{'loss': 0.2835, 'learning_rate': 2.4473684210526318e-05, 'epoch': 54.5}\n",
      "{'loss': 0.0427, 'learning_rate': 2.4210526315789474e-05, 'epoch': 55.0}\n",
      "{'loss': 0.2381, 'learning_rate': 2.394736842105263e-05, 'epoch': 55.5}\n",
      "{'loss': 0.0826, 'learning_rate': 2.368421052631579e-05, 'epoch': 56.0}\n",
      "{'loss': 0.1449, 'learning_rate': 2.342105263157895e-05, 'epoch': 56.5}\n",
      "{'loss': 0.1806, 'learning_rate': 2.3157894736842107e-05, 'epoch': 57.0}\n",
      "{'loss': 0.1891, 'learning_rate': 2.2894736842105263e-05, 'epoch': 57.5}\n",
      "{'loss': 0.1337, 'learning_rate': 2.2631578947368423e-05, 'epoch': 58.0}\n",
      "{'loss': 0.2437, 'learning_rate': 2.236842105263158e-05, 'epoch': 58.5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0935, 'learning_rate': 2.2105263157894736e-05, 'epoch': 59.0}\n",
      "{'loss': 0.1387, 'learning_rate': 2.1842105263157896e-05, 'epoch': 59.5}\n",
      "{'loss': 0.2127, 'learning_rate': 2.1578947368421053e-05, 'epoch': 60.0}\n",
      "{'loss': 0.198, 'learning_rate': 2.1315789473684212e-05, 'epoch': 60.5}\n",
      "{'loss': 0.1197, 'learning_rate': 2.105263157894737e-05, 'epoch': 61.0}\n",
      "{'loss': 0.1671, 'learning_rate': 2.078947368421053e-05, 'epoch': 61.5}\n",
      "{'loss': 0.1476, 'learning_rate': 2.0526315789473685e-05, 'epoch': 62.0}\n",
      "{'loss': 0.1874, 'learning_rate': 2.0263157894736842e-05, 'epoch': 62.5}\n",
      "{'loss': 0.1418, 'learning_rate': 2e-05, 'epoch': 63.0}\n",
      "{'loss': 0.1341, 'learning_rate': 1.9736842105263158e-05, 'epoch': 63.5}\n",
      "{'loss': 0.2222, 'learning_rate': 1.9473684210526315e-05, 'epoch': 64.0}\n",
      "{'loss': 0.1218, 'learning_rate': 1.9210526315789474e-05, 'epoch': 64.5}\n",
      "{'loss': 0.2267, 'learning_rate': 1.8947368421052634e-05, 'epoch': 65.0}\n",
      "{'loss': 0.2523, 'learning_rate': 1.868421052631579e-05, 'epoch': 65.5}\n",
      "{'loss': 0.062, 'learning_rate': 1.8421052631578947e-05, 'epoch': 66.0}\n",
      "{'loss': 0.1624, 'learning_rate': 1.8157894736842107e-05, 'epoch': 66.5}\n",
      "{'loss': 0.2208, 'learning_rate': 1.7894736842105264e-05, 'epoch': 67.0}\n",
      "{'loss': 0.1838, 'learning_rate': 1.763157894736842e-05, 'epoch': 67.5}\n",
      "{'loss': 0.1281, 'learning_rate': 1.736842105263158e-05, 'epoch': 68.0}\n",
      "{'loss': 0.1037, 'learning_rate': 1.7105263157894737e-05, 'epoch': 68.5}\n",
      "{'loss': 0.2471, 'learning_rate': 1.6842105263157896e-05, 'epoch': 69.0}\n",
      "{'loss': 0.1759, 'learning_rate': 1.6578947368421053e-05, 'epoch': 69.5}\n",
      "{'loss': 0.1728, 'learning_rate': 1.6315789473684213e-05, 'epoch': 70.0}\n",
      "{'loss': 0.1268, 'learning_rate': 1.605263157894737e-05, 'epoch': 70.5}\n",
      "{'loss': 0.2343, 'learning_rate': 1.5789473684210526e-05, 'epoch': 71.0}\n",
      "{'loss': 0.1797, 'learning_rate': 1.5526315789473686e-05, 'epoch': 71.5}\n",
      "{'loss': 0.1665, 'learning_rate': 1.5263157894736842e-05, 'epoch': 72.0}\n",
      "{'loss': 0.1251, 'learning_rate': 1.5e-05, 'epoch': 72.5}\n",
      "{'loss': 0.189, 'learning_rate': 1.4736842105263157e-05, 'epoch': 73.0}\n",
      "{'loss': 0.1727, 'learning_rate': 1.4473684210526317e-05, 'epoch': 73.5}\n",
      "{'loss': 0.1497, 'learning_rate': 1.4210526315789475e-05, 'epoch': 74.0}\n",
      "{'loss': 0.0935, 'learning_rate': 1.3947368421052631e-05, 'epoch': 74.5}\n",
      "{'loss': 0.2471, 'learning_rate': 1.3684210526315791e-05, 'epoch': 75.0}\n",
      "{'loss': 0.12, 'learning_rate': 1.3421052631578948e-05, 'epoch': 75.5}\n",
      "{'loss': 0.2559, 'learning_rate': 1.3157894736842106e-05, 'epoch': 76.0}\n",
      "{'loss': 0.1521, 'learning_rate': 1.2894736842105264e-05, 'epoch': 76.5}\n",
      "{'loss': 0.1743, 'learning_rate': 1.2631578947368422e-05, 'epoch': 77.0}\n",
      "{'loss': 0.194, 'learning_rate': 1.2368421052631579e-05, 'epoch': 77.5}\n",
      "{'loss': 0.1378, 'learning_rate': 1.2105263157894737e-05, 'epoch': 78.0}\n",
      "{'loss': 0.2306, 'learning_rate': 1.1842105263157895e-05, 'epoch': 78.5}\n",
      "{'loss': 0.0999, 'learning_rate': 1.1578947368421053e-05, 'epoch': 79.0}\n",
      "{'loss': 0.1988, 'learning_rate': 1.1315789473684212e-05, 'epoch': 79.5}\n",
      "{'loss': 0.1222, 'learning_rate': 1.1052631578947368e-05, 'epoch': 80.0}\n",
      "{'loss': 0.2003, 'learning_rate': 1.0789473684210526e-05, 'epoch': 80.5}\n",
      "{'loss': 0.1065, 'learning_rate': 1.0526315789473684e-05, 'epoch': 81.0}\n",
      "{'loss': 0.1552, 'learning_rate': 1.0263157894736843e-05, 'epoch': 81.5}\n",
      "{'loss': 0.1655, 'learning_rate': 1e-05, 'epoch': 82.0}\n",
      "{'loss': 0.1403, 'learning_rate': 9.736842105263157e-06, 'epoch': 82.5}\n",
      "{'loss': 0.201, 'learning_rate': 9.473684210526317e-06, 'epoch': 83.0}\n",
      "{'loss': 0.1927, 'learning_rate': 9.210526315789474e-06, 'epoch': 83.5}\n",
      "{'loss': 0.1212, 'learning_rate': 8.947368421052632e-06, 'epoch': 84.0}\n",
      "{'loss': 0.1731, 'learning_rate': 8.68421052631579e-06, 'epoch': 84.5}\n",
      "{'loss': 0.1329, 'learning_rate': 8.421052631578948e-06, 'epoch': 85.0}\n",
      "{'loss': 0.1045, 'learning_rate': 8.157894736842106e-06, 'epoch': 85.5}\n",
      "{'loss': 0.2131, 'learning_rate': 7.894736842105263e-06, 'epoch': 86.0}\n",
      "{'loss': 0.1208, 'learning_rate': 7.631578947368421e-06, 'epoch': 86.5}\n",
      "{'loss': 0.2189, 'learning_rate': 7.3684210526315784e-06, 'epoch': 87.0}\n",
      "{'loss': 0.2149, 'learning_rate': 7.1052631578947375e-06, 'epoch': 87.5}\n",
      "{'loss': 0.1175, 'learning_rate': 6.842105263157896e-06, 'epoch': 88.0}\n",
      "{'loss': 0.1258, 'learning_rate': 6.578947368421053e-06, 'epoch': 88.5}\n",
      "{'loss': 0.2031, 'learning_rate': 6.315789473684211e-06, 'epoch': 89.0}\n",
      "{'loss': 0.1812, 'learning_rate': 6.0526315789473685e-06, 'epoch': 89.5}\n",
      "{'loss': 0.1701, 'learning_rate': 5.789473684210527e-06, 'epoch': 90.0}\n",
      "{'loss': 0.208, 'learning_rate': 5.526315789473684e-06, 'epoch': 90.5}\n",
      "{'loss': 0.1416, 'learning_rate': 5.263157894736842e-06, 'epoch': 91.0}\n",
      "{'loss': 0.2024, 'learning_rate': 5e-06, 'epoch': 91.5}\n",
      "{'loss': 0.1056, 'learning_rate': 4.736842105263159e-06, 'epoch': 92.0}\n",
      "{'loss': 0.1761, 'learning_rate': 4.473684210526316e-06, 'epoch': 92.5}\n",
      "{'loss': 0.1542, 'learning_rate': 4.210526315789474e-06, 'epoch': 93.0}\n",
      "{'loss': 0.1389, 'learning_rate': 3.9473684210526315e-06, 'epoch': 93.5}\n",
      "{'loss': 0.1769, 'learning_rate': 3.6842105263157892e-06, 'epoch': 94.0}\n",
      "{'loss': 0.1551, 'learning_rate': 3.421052631578948e-06, 'epoch': 94.5}\n",
      "{'loss': 0.1624, 'learning_rate': 3.1578947368421056e-06, 'epoch': 95.0}\n",
      "{'loss': 0.1994, 'learning_rate': 2.8947368421052634e-06, 'epoch': 95.5}\n",
      "{'loss': 0.153, 'learning_rate': 2.631578947368421e-06, 'epoch': 96.0}\n",
      "{'loss': 0.1765, 'learning_rate': 2.3684210526315793e-06, 'epoch': 96.5}\n",
      "{'loss': 0.1744, 'learning_rate': 2.105263157894737e-06, 'epoch': 97.0}\n",
      "{'loss': 0.1792, 'learning_rate': 1.8421052631578946e-06, 'epoch': 97.5}\n",
      "{'loss': 0.1515, 'learning_rate': 1.5789473684210528e-06, 'epoch': 98.0}\n",
      "{'loss': 0.1641, 'learning_rate': 1.3157894736842106e-06, 'epoch': 98.5}\n",
      "{'loss': 0.127, 'learning_rate': 1.0526315789473685e-06, 'epoch': 99.0}\n",
      "{'loss': 0.194, 'learning_rate': 7.894736842105264e-07, 'epoch': 99.5}\n",
      "{'loss': 0.1237, 'learning_rate': 5.263157894736843e-07, 'epoch': 100.0}\n",
      "{'train_runtime': 1005.5212, 'train_samples_per_second': 5.868, 'train_steps_per_second': 0.199, 'train_loss': 0.26259448371827604, 'epoch': 100.0}\n"
     ]
    }
   ],
   "source": [
    "y_probs, y_trues = [], []\n",
    "for i in range(len(X)):\n",
    "    \n",
    "    print(f\"Fitting model using fold {i} as out of fold data.\")\n",
    "    \n",
    "    # Identify train folds and shuffle samples\n",
    "    X_train, y_train = np.concatenate(X[0:i] + X[i+1:], axis=0), np.concatenate(y[0:i] + y[i+1:], axis=0)\n",
    "    indices = np.arange(len(y_train))\n",
    "    np.random.shuffle(indices)\n",
    "    X_train, y_train = X_train[indices], y_train[indices]\n",
    "    \n",
    "    # Identify test folds\n",
    "    X_test, y_test = X[i], y[i]\n",
    "    \n",
    "    # Format text and label data as HuggingFace dataset\n",
    "    train_dataset = Dataset.from_dict({\"text\": X_train, \"label\": y_train})\n",
    "    test_dataset = Dataset.from_dict({\"text\": X_test, \"label\": y_test})\n",
    "    \n",
    "    # Load model and tokenizer\n",
    "    # This will reset the model weights with each new iteration\n",
    "    tokenizer = AutoTokenizer.from_pretrained(lm_path)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        lm_path,\n",
    "        num_labels=2,\n",
    "        return_dict=True,\n",
    "        problem_type=\"single_label_classification\"\n",
    "    )\n",
    "    \n",
    "    # Define function to tokenize text\n",
    "    def tokenize_function(batch):\n",
    "        \n",
    "        return tokenizer(\n",
    "            batch[\"text\"],\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=max_seq_len\n",
    "        )\n",
    "    \n",
    "    # Tokenize train dataset\n",
    "    train_dataset = train_dataset.map(\n",
    "        tokenize_function,\n",
    "        batched=True,\n",
    "        remove_columns=[\"text\"],\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    train_dataset.set_format(\"pt\")\n",
    "    \n",
    "    # Tokenize test dataset\n",
    "    test_dataset = test_dataset.map(\n",
    "        tokenize_function,\n",
    "        batched=True,\n",
    "        remove_columns=[\"text\"],\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    test_dataset.set_format(\"pt\")\n",
    "    \n",
    "    # Define training arguments\n",
    "    training_args= TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        gradient_accumulation_steps=accumulation_steps,\n",
    "        warmup_steps=warmup_steps,\n",
    "        logging_steps=logging_steps,\n",
    "        weight_decay=weight_decay,\n",
    "        learning_rate=lr,\n",
    "        seed=seed,\n",
    "        adam_beta1=adam_beta1,\n",
    "        adam_beta2=adam_beta2,\n",
    "        adam_epsilon=adam_epsilon,\n",
    "        dataloader_num_workers=num_workers,\n",
    "        fp16=fp16,\n",
    "        logging_strategy=\"steps\",\n",
    "        save_strategy=\"no\",\n",
    "        lr_scheduler_type='linear',\n",
    "        optim=\"adamw_torch\",\n",
    "        run_name='lf',\n",
    "        do_eval=False,\n",
    "        fp16_full_eval=False,\n",
    "        sharded_ddp=False,\n",
    "        gradient_checkpointing=True,\n",
    "        load_best_model_at_end=True,\n",
    "        prediction_loss_only=False,\n",
    "        disable_tqdm=True,\n",
    "        logging_dir=None,\n",
    "    )\n",
    "    \n",
    "    # Define model training\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    trainer.train()\n",
    "    \n",
    "    # Predict on test dataset\n",
    "    output = trainer.predict(test_dataset)\n",
    "    labels = output.label_ids\n",
    "    y_prob = torch.sigmoid(torch.tensor(output.predictions).double()).numpy()[:, 1]\n",
    "\n",
    "    # Save scores and labels\n",
    "    y_probs.append(y_prob)\n",
    "    y_trues.append(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da93cef",
   "metadata": {},
   "source": [
    "##### Save Model Probabilities on Test Folds and True Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bbff8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/lfm_y_trues.pkl', 'wb') as f:\n",
    "    pickle.dump(y_trues, f)\n",
    "\n",
    "with open('results/lfm_y_probs.pkl', 'wb') as f:\n",
    "    pickle.dump(y_probs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4d8469",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transcripts",
   "language": "python",
   "name": "transcripts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
