{"cells":[{"cell_type":"markdown","id":"6ea00513","metadata":{"id":"6ea00513"},"source":["### Fine-Tune Language Models\n","\n","- Joel Stremmel\n","- 04-24-23\n","\n","##### About\n","\n","Fine-Tune pretrained language models on the formatted data using K-Fold Cross-Validation and save the scores."]},{"cell_type":"markdown","source":["##### Set Parameters"],"metadata":{"id":"VYcPr_6eBBDt"},"id":"VYcPr_6eBBDt"},{"cell_type":"code","source":["size = \"large\"\n","params = {\n","    \"env\": {\"colab\": True, \"require_high_ram\": True},\n","    \"data\": {\"add_summaries\": False},\n","    \"training\": {\n","        \"lr\": 0.000005,\n","        \"weight_decay\": 0.01,\n","        \"adam_beta1\": 0.9,\n","        \"adam_beta2\": 0.999,\n","        \"adam_epsilon\": 0.00000001,\n","        \"warmup_steps\": 10,\n","        \"logging_steps\": 1,\n","        \"num_workers\": 2,\n","        \"epochs\": 200,\n","        \"early_stopping_patience\": 5,\n","    },\n","    \"evaluation\": {\n","        \"evaluation_strategy\": \"epoch\",\n","        \"save_strategy\": \"epoch\",\n","        \"fp16_full_eval\": False,\n","        \"eval_accumulation_steps\": 100,\n","    },\n","    \"small_models\": {\n","          'gpt2': {\n","            'path': 'gpt2',\n","            'fp16': False,\n","            'max_seq_len': 1024,\n","            'batch_size': 1,\n","            'accumulation_steps': 16,\n","            'gradient_checkpointing': True,\n","            'type': 'gpt'\n","        },\n","        'roberta_base': {\n","            'path': 'roberta-base',\n","            'fp16': True,\n","            'max_seq_len': 512,\n","            'batch_size': 2,\n","            'accumulation_steps': 8,\n","            'gradient_checkpointing': True,\n","            'type': 'mlm'\n","        },\n","        'lf_mini': {\n","            'path': 'kiddothe2b/longformer-mini-1024',\n","            'max_seq_len': 1024,\n","            'fp16': True,\n","            'batch_size': 1,\n","            'accumulation_steps': 16,\n","            'gradient_checkpointing': False,\n","            'type': 'mlm'\n","        },\n","        \"flan_t5_small\": {\n","            \"path\": \"google/flan-t5-small\",\n","            \"max_seq_len\": 1024,\n","            \"output_max_seq_len\": 5,\n","            \"fp16\": False,\n","            \"batch_size\": 1,\n","            \"accumulation_steps\": 16,\n","            \"gradient_checkpointing\": False,\n","            \"type\": \"seq2seq\",\n","        }\n","    },\n","    \"large_models\": {\n","        \"bb_large\": {\n","            \"path\": \"google/bigbird-roberta-large\",\n","            \"max_seq_len\": 4096,\n","            \"fp16\": True,\n","            \"batch_size\": 16,\n","            \"accumulation_steps\": 1,\n","            \"gradient_checkpointing\": True,\n","            \"type\": \"mlm\",\n","        },\n","        \"roberta_large\": {\n","            \"path\": \"roberta-large\",\n","            \"fp16\": True,\n","            \"max_seq_len\": 512,\n","            \"batch_size\": 16,\n","            \"accumulation_steps\": 1,\n","            \"gradient_checkpointing\": False,\n","            \"type\": \"mlm\",\n","        },\n","    },\n","    \"io\": {\n","        \"results_dir\": \"/content/drive/MyDrive/nlp4psychotherapy/results\",\n","        \"input_dir\": \"/content/drive/MyDrive/nlp4psychotherapy/data\",\n","        \"model_output_dir\": \"/content/drive/MyDrive/nlp4psychotherapy/model_output\",\n","    },\n","    \"augmentation\": {\n","        \"add_synthetic\": False,\n","        \"aug_p\": 0.2,\n","        \"glove_file\": \"data/glove.6B.50d.txt\",\n","        \"glove_zip\": \"data/glove.6B.zip\",\n","        \"glove_url\": \"http://nlp.stanford.edu/data/glove.6B.zip\",\n","    },\n","    \"random\": {\"seed\": 42},\n","}\n","\n","#         \"lf_base\": {\n","#             \"path\": \"allenai/longformer-base-4096\",\n","#             \"max_seq_len\": 4096,\n","#             \"fp16\": True,\n","#             \"batch_size\": 4,\n","#             \"accumulation_steps\": 4,\n","#             \"gradient_checkpointing\": False,\n","#             \"type\": \"mlm\",\n","#         },\n","#         \"bb_base\": {\n","#             \"max_seq_len\": 4096,\n","#             \"fp16\": True,\n","#             \"batch_size\": 4,\n","#             \"accumulation_steps\": 4,\n","#             \"gradient_checkpointing\": False,\n","#             \"type\": \"mlm\",\n","#         },\n","#         \"gpt_neo_1_3b\": {\n","#             \"path\": \"EleutherAI/gpt-neo-1.3B\",\n","#             \"max_seq_len\": 2048,\n","#             \"fp16\": False,\n","#             \"batch_size\": 1,\n","#             \"accumulation_steps\": 16,\n","#             \"gradient_checkpointing\": False,\n","#             \"type\": \"gpt\",\n","#         },\n","#         \"flan_t5_large\": {\n","#             \"path\": \"google/flan-t5-large\",\n","#             \"max_seq_len\": 1024,\n","#             \"output_max_seq_len\": 6,\n","#             \"fp16\": False,\n","#             \"batch_size\": 1,\n","#             \"accumulation_steps\": 16,\n","#             \"gradient_checkpointing\": False,\n","#             \"type\": \"seq2seq\",\n","#         },"],"metadata":{"id":"D58Rt3YCBAdg","executionInfo":{"status":"ok","timestamp":1682353943906,"user_tz":420,"elapsed":779,"user":{"displayName":"Joel Stremmel","userId":"12962611405624586431"}}},"id":"D58Rt3YCBAdg","execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["##### Mount Google Drive and Install Requirements if Using Colab"],"metadata":{"id":"Mpu_ZHMpA8ez"},"id":"Mpu_ZHMpA8ez"},{"cell_type":"code","source":["if params[\"env\"][\"colab\"]:\n","\n","    import os\n","    from google.colab import drive\n","    drive.mount(\"/content/drive\")\n","    !pip install -q -r \"/content/drive/MyDrive/nlp4psychotherapy/requirements.txt\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GhAWMTPjA6qn","executionInfo":{"status":"ok","timestamp":1682353953826,"user_tz":420,"elapsed":7579,"user":{"displayName":"Joel Stremmel","userId":"12962611405624586431"}},"outputId":"339e17e2-fcaf-4cd2-ffdd-cbeeba4614b3"},"id":"GhAWMTPjA6qn","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","id":"9ac2c7a9","metadata":{"id":"9ac2c7a9"},"source":["##### Imports"]},{"cell_type":"code","execution_count":3,"id":"dd145b3a","metadata":{"id":"dd145b3a","executionInfo":{"status":"ok","timestamp":1682353957779,"user_tz":420,"elapsed":3957,"user":{"displayName":"Joel Stremmel","userId":"12962611405624586431"}}},"outputs":[],"source":["import os\n","import re\n","import glob\n","import pickle\n","import torch\n","import numpy as np\n","import pandas as pd\n","from datasets import Dataset\n","from transformers import (\n","    AutoTokenizer,\n","    AutoModelForSequenceClassification,\n","    GPT2ForSequenceClassification,\n","    GPTNeoForSequenceClassification,\n","    AutoModelForSeq2SeqLM,\n","    Seq2SeqTrainer,\n","    Seq2SeqTrainingArguments,\n","    Trainer,\n","    TrainingArguments,\n","    EarlyStoppingCallback,\n",")"]},{"cell_type":"markdown","id":"171b48fd","metadata":{"id":"171b48fd"},"source":["##### Check Colab Runtime"]},{"cell_type":"code","execution_count":4,"id":"1191196c","metadata":{"id":"1191196c","executionInfo":{"status":"ok","timestamp":1682353957780,"user_tz":420,"elapsed":18,"user":{"displayName":"Joel Stremmel","userId":"12962611405624586431"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"487c1001-fb27-4a08-fe36-c405e3349005"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Apr 24 16:32:37 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   32C    P0    45W / 400W |      0MiB / 40960MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","Your runtime has 89.6 gigabytes of available RAM\n","\n","You are using a high-RAM runtime!\n"]}],"source":["if params[\"env\"][\"colab\"]:\n","    gpu_info = !nvidia-smi\n","    gpu_info = \"\\n\".join(gpu_info)\n","    if gpu_info.find(\"failed\") >= 0:\n","        print(\"Not connected to a GPU\")\n","    else:\n","        print(gpu_info)\n","\n","if params[\"env\"][\"require_high_ram\"]:\n","    from psutil import virtual_memory\n","\n","    ram_gb = virtual_memory().total / 1e9\n","    print(\"Your runtime has {:.1f} gigabytes of available RAM\\n\".format(ram_gb))\n","\n","    if ram_gb < 20:\n","        print(\"Not using a high-RAM runtime\")\n","    else:\n","        print(\"You are using a high-RAM runtime!\")"]},{"cell_type":"markdown","id":"48c1718e","metadata":{"id":"48c1718e"},"source":["##### Disable Tokenizer Parallelism\n","This is mostly to avoid warnings."]},{"cell_type":"code","execution_count":5,"id":"dc6fc432","metadata":{"id":"dc6fc432","executionInfo":{"status":"ok","timestamp":1682353957781,"user_tz":420,"elapsed":11,"user":{"displayName":"Joel Stremmel","userId":"12962611405624586431"}}},"outputs":[],"source":["os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""]},{"cell_type":"markdown","id":"2f78b64c","metadata":{"id":"2f78b64c"},"source":["##### Load Formatted Data"]},{"cell_type":"code","execution_count":6,"id":"710a85d0","metadata":{"id":"710a85d0","executionInfo":{"status":"ok","timestamp":1682353957782,"user_tz":420,"elapsed":11,"user":{"displayName":"Joel Stremmel","userId":"12962611405624586431"}}},"outputs":[],"source":["if params[\"data\"][\"add_summaries\"]:\n","    with open(os.path.join(params[\"io\"][\"input_dir\"], \"Xwsum_folds.pkl\"), \"rb\") as f:\n","        X_folds = pickle.load(f)\n","\n","else:\n","    with open(os.path.join(params[\"io\"][\"input_dir\"], \"X_folds.pkl\"), \"rb\") as f:\n","        X_folds = pickle.load(f)\n","\n","    with open(os.path.join(params[\"io\"][\"input_dir\"], \"y_folds.pkl\"), \"rb\") as f:\n","        y_folds = pickle.load(f)"]},{"cell_type":"markdown","id":"5d6b559a","metadata":{"id":"5d6b559a"},"source":["##### Check Data Shape"]},{"cell_type":"code","execution_count":7,"id":"bb7c83b6","metadata":{"id":"bb7c83b6","executionInfo":{"status":"ok","timestamp":1682353957782,"user_tz":420,"elapsed":11,"user":{"displayName":"Joel Stremmel","userId":"12962611405624586431"}}},"outputs":[],"source":["assert len(X_folds) == len(y_folds), \"Expected the same number of folds in X and y.\"\n","X = list(X_folds.values())\n","y = list(y_folds.values())"]},{"cell_type":"markdown","id":"aac7cd9d","metadata":{"id":"aac7cd9d"},"source":["##### Check Target Prevalence"]},{"cell_type":"code","execution_count":8,"id":"2164340a","metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1682353957782,"user":{"displayName":"Joel Stremmel","userId":"12962611405624586431"},"user_tz":420},"id":"2164340a","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b21c8a14-5f91-4d25-fe2c-f1ceb855b45c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Target prevalance: 0.517.\n"]}],"source":["print(f\"Target prevalance: {round(np.mean(np.concatenate(y)), 3)}.\")"]},{"cell_type":"markdown","id":"15ff6576","metadata":{"id":"15ff6576"},"source":["##### Check that GPU is Available"]},{"cell_type":"code","execution_count":9,"id":"617bd083","metadata":{"id":"617bd083","executionInfo":{"status":"ok","timestamp":1682353960458,"user_tz":420,"elapsed":2684,"user":{"displayName":"Joel Stremmel","userId":"12962611405624586431"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b38912ef-06f5-4d15-b494-f1d908bb8fea"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.0.0+cu118\n"]}],"source":["assert torch.cuda.is_available(), \"Run this script on a GPU.\"\n","print(torch.__version__)"]},{"cell_type":"markdown","id":"85f2951e","metadata":{"id":"85f2951e"},"source":["##### Select and Preprocess Text and Fit Model to Each Data Fold"]},{"cell_type":"code","execution_count":null,"id":"45cc6d29","metadata":{"id":"45cc6d29","colab":{"base_uri":"https://localhost:8080/","height":292,"referenced_widgets":["055f1e4d78c34b358b7b81c34a35dcca","9c6b076f21fb4581852d9e6cef38348b","da011d2a8f054c0c96de351638be8082","2aa352d169574872b54af336891b77a5","03523b12325b4de9815c7786ab6b24f9","1fb706a59b014f8fb82039cf3eee20d3","f5a04415a98e4948967286b763ecdec4","c877a08bf9584693a970409093b9f11f","100d64ce9565411281e845f812678a47","ab96b12d0cf2442e97784bf611a84e0f","7abbf4cbad6a4d2e96205fe15cb9a187","675ae5f64baf42aa89a278da48c9b113","34b46a8dcf914145967c6506bc8f227b","9cdcbfc051b4432a82ed32cfc1de06ca","6dc28dec9223483a944cd60e6f0577a4","63b5f171c55b405cae5d28dffca419c9","b756fca0b13142738a4a4e84a9f5dd02","66a96781dc4c4444b8a19900c441732d","1ab9d46bcfdc456abf4e4dc5a7bb885f","81684d60d2ad4c398fa75fdcbb502fe4","11d5e337a7f544a2b9407487c629ed77","df66dc11f89245da91d0c468efc5e0b8","f4861a75799a4bcfadb2c2bc4b437920","111646935dab4b4d8ca02f469f036c7b","cf2b268b067e4faf8f1a0b843c1658df","f54b81c0c07d41b0a5d5382770c57ac3","1a7459d4d27b4acb871e25c7268f2e93","e7c39f43f441428cba8623dbe50fc35a","284ed0fb376b471591e20400610348a6","8bfef4076a5848e286a56a3a4c6befaf","fd2d73720c1249d38e473e02a89aa506","8712b85e4dce48639b9be816ec9883a1","090908704adb4e4189b9834d932f0abe"]},"outputId":"f7fac1c2-e458-41b9-e331-3fef80bcb58f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting model: bb_large using fold 0 as out of fold test data.\n","Train data sizes: (34, 34).\n","Val data sizes: (13, 13).\n","Test data sizes: (13, 13).\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/numpy/lib/function_base.py:5030: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  arr = asarray(arr)\n","Some weights of the model checkpoint at google/bigbird-roberta-large were not used when initializing BigBirdForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-large and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/34 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"055f1e4d78c34b358b7b81c34a35dcca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/13 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"675ae5f64baf42aa89a278da48c9b113"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/13 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4861a75799a4bcfadb2c2bc4b437920"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["{'loss': 0.7145, 'learning_rate': 5.000000000000001e-07, 'epoch': 0.33}\n","{'loss': 0.7245, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.67}\n","{'loss': 0.8362, 'learning_rate': 1.5e-06, 'epoch': 1.0}\n","{'eval_loss': 0.7054911851882935, 'eval_runtime': 1.4204, 'eval_samples_per_second': 9.153, 'eval_steps_per_second': 0.704, 'epoch': 1.0}\n"]}],"source":["y_probs, y_trues = {}, {}\n","for model in params[f\"{size}_models\"].keys():\n","\n","    y_probs[model], y_trues[model] = [], []\n","    for i in range(len(X)):\n","        \n","        # Print model and fold\n","        print(f\"Fitting model: {model} using fold {i} as out of fold test data.\")\n","\n","        # Identify train and test folds\n","        X_train_temp, y_train_temp = X[0:i] + X[i + 1 :], y[0:i] + y[i + 1 :]\n","        X_test, y_test = X[i], y[i]\n","\n","        # Select a validation fold at random\n","        indices_temp = np.arange(len(y_train_temp))\n","        val_index = np.random.choice(indices_temp)\n","        X_val, y_val = X_train_temp[val_index], y_train_temp[val_index]\n","\n","        # Identify the training folds as the indices not including the validation index\n","        # Concatenate all examples in the training folds to form the full training set\n","        X_train = np.concatenate(np.delete(X_train_temp, val_index), axis=0)\n","        y_train = np.concatenate(np.delete(y_train_temp, val_index), axis=0)\n","\n","        # Shuffle training data\n","        indices = np.arange(len(y_train))\n","        np.random.shuffle(indices)\n","        X_train, y_train = X_train[indices], y_train[indices]\n","\n","        # Print data shapes\n","        print(f\"Train data sizes: {len(X_train), len(y_train)}.\")\n","        print(f\"Val data sizes: {len(X_val), len(y_val)}.\")\n","        print(f\"Test data sizes: {len(X_test), len(y_test)}.\")\n","\n","        # Format text and label data as HuggingFace dataset\n","        if params[f\"{size}_models\"][model][\"type\"] == \"seq2seq\":\n","            train_dataset = Dataset.from_dict(\n","                {\"text\": X_train, \"label_ids\": [str(label) for label in y_train]}\n","            )\n","            val_dataset = Dataset.from_dict(\n","                {\"text\": X_val, \"label_ids\": [str(label) for label in y_val]}\n","            )\n","            test_dataset = Dataset.from_dict(\n","                {\"text\": X_test, \"label_ids\": [str(label) for label in y_test]}\n","            )\n","\n","        else:\n","            train_dataset = Dataset.from_dict({\"text\": X_train, \"label\": y_train})\n","            val_dataset = Dataset.from_dict({\"text\": X_val, \"label\": y_val})\n","            test_dataset = Dataset.from_dict({\"text\": X_test, \"label\": y_test})\n","\n","        # Load tokenizer\n","        tokenizer = AutoTokenizer.from_pretrained(\n","            params[f\"{size}_models\"][model][\"path\"]\n","        )\n","\n","        # Load model by model type\n","        if params[f\"{size}_models\"][model][\"type\"] == \"mlm\":\n","            \n","            # Load masked language model with a sequence classification head\n","            lm = AutoModelForSequenceClassification.from_pretrained(\n","                params[f\"{size}_models\"][model][\"path\"],\n","                num_labels=2,\n","                return_dict=True,\n","                problem_type=\"single_label_classification\",\n","            )\n","\n","        elif params[f\"{size}_models\"][model][\"type\"] == \"gpt\":\n","            \n","            # Use the end of sentence token as a pad token for GPT models\n","            tokenizer.pad_token = tokenizer.eos_token\n","\n","            if model == \"gpt2\":\n","                \n","                # Load GPT-2\n","                lm = GPT2ForSequenceClassification.from_pretrained(\n","                    params[f\"{size}_models\"][model][\"path\"],\n","                    num_labels=2,\n","                    return_dict=True,\n","                    problem_type=\"single_label_classification\",\n","                )\n","\n","            elif \"gpt_neo\" in model:\n","                \n","                # Load a GPT Neo version\n","                lm = GPTNeoForSequenceClassification.from_pretrained(\n","                    params[f\"{size}_models\"][model][\"path\"],\n","                    num_labels=2,\n","                    return_dict=True,\n","                    problem_type=\"single_label_classification\",\n","                )\n","\n","            else:\n","                raise ValueError(\"Expected GPT model to be gpt2 or a gpt_neo version.\")\n","\n","        elif params[f\"{size}_models\"][model][\"type\"] == \"seq2seq\":\n","            lm = AutoModelForSeq2SeqLM.from_pretrained(\n","                params[f\"{size}_models\"][model][\"path\"]\n","            )\n","        else:\n","            raise ValueError(\n","                f\"Unexpected model type: {params[f'{size}_models'][model]['path']}.\"\n","            )\n","\n","        # Define function to preprocess and tokenize text\n","        if params[f\"{size}_models\"][model][\"type\"] == \"seq2seq\":\n","\n","            def preprocess_function(\n","                sample, padding=\"max_length\", output_max_seq_len=20\n","            ):\n","                \n","                # Add prefix to the input for t5\n","                inputs = [\n","                    \"Classify this text as either 1 or 0: \" + item\n","                    for item in sample[\"text\"]\n","                ]\n","\n","                # tokenize inputs\n","                model_inputs = tokenizer(\n","                    inputs,\n","                    max_length=params[f\"{size}_models\"][model][\"max_seq_len\"],\n","                    padding=padding,\n","                    truncation=True,\n","                )\n","\n","                # Tokenize targets with the `text_target` keyword argument\n","                labels = tokenizer(\n","                    text_target=sample[\"label_ids\"],\n","                    max_length=params[f\"{size}_models\"][model][\"output_max_seq_len\"],\n","                    padding=padding,\n","                    truncation=True,\n","                )\n","\n","                # If we are padding here, replace all tokenizer.pad_token_id in the labels by -100 when we want to ignore\n","                # padding in the loss.\n","                if padding == \"max_length\":\n","                    labels[\"input_ids\"] = [\n","                        [(l if l != tokenizer.pad_token_id else -100) for l in label]\n","                        for label in labels[\"input_ids\"]\n","                    ]\n","\n","                model_inputs[\"label_ids\"] = labels[\"input_ids\"]\n","\n","                return model_inputs\n","\n","        else:\n","\n","            def preprocess_function(batch):\n","                return tokenizer(\n","                    batch[\"text\"],\n","                    padding=\"max_length\",\n","                    truncation=True,\n","                    max_length=params[f\"{size}_models\"][model][\"max_seq_len\"],\n","                )\n","\n","        # Preprocess datasets\n","        train_dataset = train_dataset.map(\n","            preprocess_function,\n","            batched=True,\n","            remove_columns=[\"text\"],\n","            batch_size=params[f\"{size}_models\"][model][\"batch_size\"],\n","        )\n","        train_dataset.set_format(\"pt\")\n","        val_dataset = val_dataset.map(\n","            preprocess_function,\n","            batched=True,\n","            remove_columns=[\"text\"],\n","            batch_size=params[f\"{size}_models\"][model][\"batch_size\"],\n","        )\n","        val_dataset.set_format(\"pt\")\n","        test_dataset = test_dataset.map(\n","            preprocess_function,\n","            batched=True,\n","            remove_columns=[\"text\"],\n","            batch_size=params[f\"{size}_models\"][model][\"batch_size\"],\n","        )\n","        test_dataset.set_format(\"pt\")\n","\n","        # Define training arguments\n","        training_args = TrainingArguments(\n","            output_dir=params[\"io\"][\"model_output_dir\"],\n","            num_train_epochs=params[\"training\"][\"epochs\"],\n","            warmup_steps=params[\"training\"][\"warmup_steps\"],\n","            logging_steps=params[\"training\"][\"logging_steps\"],\n","            weight_decay=params[\"training\"][\"weight_decay\"],\n","            learning_rate=params[\"training\"][\"lr\"],\n","            adam_beta1=params[\"training\"][\"adam_beta1\"],\n","            adam_beta2=params[\"training\"][\"adam_beta2\"],\n","            adam_epsilon=params[\"training\"][\"adam_epsilon\"],\n","            dataloader_num_workers=params[\"training\"][\"num_workers\"],\n","            seed=params[\"random\"][\"seed\"],\n","            run_name=params[f\"{size}_models\"][model],\n","            fp16=params[f\"{size}_models\"][model][\"fp16\"],\n","            gradient_checkpointing=params[f\"{size}_models\"][model][\n","                \"gradient_checkpointing\"\n","            ],\n","            per_device_train_batch_size=params[f\"{size}_models\"][model][\"batch_size\"],\n","            per_device_eval_batch_size=params[f\"{size}_models\"][model][\"batch_size\"],\n","            gradient_accumulation_steps=params[f\"{size}_models\"][model][\n","                \"accumulation_steps\"\n","            ],\n","            evaluation_strategy=params[\"evaluation\"][\"evaluation_strategy\"],\n","            save_strategy=params[\"evaluation\"][\"save_strategy\"],\n","            fp16_full_eval=params[\"evaluation\"][\"fp16_full_eval\"],\n","            eval_accumulation_steps=params[\"evaluation\"][\"eval_accumulation_steps\"],\n","            save_total_limit=1,\n","            logging_strategy=\"steps\",\n","            lr_scheduler_type=\"linear\",\n","            optim=\"adamw_torch\",\n","            sharded_ddp=False,\n","            prediction_loss_only=False,\n","            load_best_model_at_end=True,\n","            disable_tqdm=True,\n","            logging_dir=None,\n","        )\n","        \n","        # Define special training arguments\n","        if params[f\"{size}_models\"][model][\"type\"] == \"seq2seq\":\n","            training_args.generation_max_length = params[f\"{size}_models\"][model][\"output_max_seq_len\"]\n","            training_args.predict_with_generate = True\n","            training_args.generation_num_beams = None\n","\n","        # Define early stopping callback\n","        early_stopping = EarlyStoppingCallback(\n","            early_stopping_patience=params[\"training\"][\"early_stopping_patience\"]\n","        )\n","\n","        # Define trainer\n","        if params[f\"{size}_models\"][model][\"type\"] == \"seq2seq\":\n","            trainer = Seq2SeqTrainer(\n","                model=lm,\n","                args=training_args,\n","                train_dataset=train_dataset,\n","                eval_dataset=val_dataset,\n","                callbacks=[early_stopping],\n","            )\n","        else:\n","            trainer = Trainer(\n","                model=lm,\n","                args=training_args,\n","                train_dataset=train_dataset,\n","                eval_dataset=val_dataset,\n","                callbacks=[early_stopping],\n","            )\n","\n","        # Train model\n","        trainer.train()\n","\n","        # Predict on test dataset for seq2seq models\n","        if params[f\"{size}_models\"][model][\"type\"] == \"seq2seq\":\n","            \n","            # Predict on test dataset with greedy generation\n","            output = trainer.predict(\n","                test_dataset,\n","                do_sample=False,\n","                max_length=params[f\"{size}_models\"][model][\"output_max_seq_len\"],\n","                early_stopping=True,\n","            )\n","            preds_decoded = tokenizer.batch_decode(\n","                output.predictions, skip_special_tokens=True\n","            )\n","            labels = np.where(\n","                output.label_ids != -100, output.label_ids, tokenizer.pad_token_id\n","            )\n","            labels_decoded = tokenizer.batch_decode(labels, skip_special_tokens=False)\n","\n","            # Convert preds to ints\n","            # We allow additional characters to be generated by check\n","            # that the first one is a 1 or 0\n","            preds = []\n","            for pred in preds_decoded:\n","                if pred[0] == \"1\":\n","                    preds.append(1)\n","                elif pred[0] == \"0\":\n","                    preds.append(0)\n","                else:\n","                    print(f\"Got unexpected pred: {pred}.\")\n","                    preds.append(np.random.choice([0, 1]))\n","\n","            # Save scores and labels\n","            # The labels may contain additional characters, but the first should be\n","            # a 1 or 0\n","            y_probs[model].append(preds)\n","            y_trues[model].append([int(label[0]) for label in labels_decoded])\n","\n","        # Predict on test set for other model types\n","        else:\n","            # Generate scores\n","            output = trainer.predict(test_dataset)\n","            labels = output.label_ids\n","            y_prob = torch.sigmoid(torch.tensor(output.predictions).double()).numpy()[\n","                :, 1\n","            ]\n","\n","            # Save scores and labels\n","            y_probs[model].append(y_prob)\n","            y_trues[model].append(labels)\n","\n","        # Empty cuda cache\n","        torch.cuda.empty_cache()"]},{"cell_type":"markdown","id":"7da93cef","metadata":{"id":"7da93cef"},"source":["##### Save Model Scores on Test Folds and True Labels"]},{"cell_type":"code","execution_count":null,"id":"6bbff8d9","metadata":{"id":"6bbff8d9"},"outputs":[],"source":["with open(os.path.join(params[\"io\"][\"results_dir\"], \"lm_y_trues.pkl\"), \"wb\") as f:\n","    pickle.dump(y_trues, f)\n","\n","with open(os.path.join(params[\"io\"][\"results_dir\"], \"lm_y_probs.pkl\"), \"wb\") as f:\n","    pickle.dump(y_probs, f)"]},{"cell_type":"code","execution_count":null,"id":"602b97a1","metadata":{"id":"602b97a1"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","provenance":[],"machine_shape":"hm"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"055f1e4d78c34b358b7b81c34a35dcca":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9c6b076f21fb4581852d9e6cef38348b","IPY_MODEL_da011d2a8f054c0c96de351638be8082","IPY_MODEL_2aa352d169574872b54af336891b77a5"],"layout":"IPY_MODEL_03523b12325b4de9815c7786ab6b24f9"}},"9c6b076f21fb4581852d9e6cef38348b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1fb706a59b014f8fb82039cf3eee20d3","placeholder":"​","style":"IPY_MODEL_f5a04415a98e4948967286b763ecdec4","value":"Map: 100%"}},"da011d2a8f054c0c96de351638be8082":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_c877a08bf9584693a970409093b9f11f","max":34,"min":0,"orientation":"horizontal","style":"IPY_MODEL_100d64ce9565411281e845f812678a47","value":34}},"2aa352d169574872b54af336891b77a5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab96b12d0cf2442e97784bf611a84e0f","placeholder":"​","style":"IPY_MODEL_7abbf4cbad6a4d2e96205fe15cb9a187","value":" 34/34 [00:00&lt;00:00, 270.80 examples/s]"}},"03523b12325b4de9815c7786ab6b24f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"1fb706a59b014f8fb82039cf3eee20d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5a04415a98e4948967286b763ecdec4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c877a08bf9584693a970409093b9f11f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"100d64ce9565411281e845f812678a47":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ab96b12d0cf2442e97784bf611a84e0f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7abbf4cbad6a4d2e96205fe15cb9a187":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"675ae5f64baf42aa89a278da48c9b113":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_34b46a8dcf914145967c6506bc8f227b","IPY_MODEL_9cdcbfc051b4432a82ed32cfc1de06ca","IPY_MODEL_6dc28dec9223483a944cd60e6f0577a4"],"layout":"IPY_MODEL_63b5f171c55b405cae5d28dffca419c9"}},"34b46a8dcf914145967c6506bc8f227b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b756fca0b13142738a4a4e84a9f5dd02","placeholder":"​","style":"IPY_MODEL_66a96781dc4c4444b8a19900c441732d","value":"Map:   0%"}},"9cdcbfc051b4432a82ed32cfc1de06ca":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ab9d46bcfdc456abf4e4dc5a7bb885f","max":13,"min":0,"orientation":"horizontal","style":"IPY_MODEL_81684d60d2ad4c398fa75fdcbb502fe4","value":13}},"6dc28dec9223483a944cd60e6f0577a4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_11d5e337a7f544a2b9407487c629ed77","placeholder":"​","style":"IPY_MODEL_df66dc11f89245da91d0c468efc5e0b8","value":" 0/13 [00:00&lt;?, ? examples/s]"}},"63b5f171c55b405cae5d28dffca419c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"b756fca0b13142738a4a4e84a9f5dd02":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66a96781dc4c4444b8a19900c441732d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1ab9d46bcfdc456abf4e4dc5a7bb885f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81684d60d2ad4c398fa75fdcbb502fe4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"11d5e337a7f544a2b9407487c629ed77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df66dc11f89245da91d0c468efc5e0b8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f4861a75799a4bcfadb2c2bc4b437920":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_111646935dab4b4d8ca02f469f036c7b","IPY_MODEL_cf2b268b067e4faf8f1a0b843c1658df","IPY_MODEL_f54b81c0c07d41b0a5d5382770c57ac3"],"layout":"IPY_MODEL_1a7459d4d27b4acb871e25c7268f2e93"}},"111646935dab4b4d8ca02f469f036c7b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7c39f43f441428cba8623dbe50fc35a","placeholder":"​","style":"IPY_MODEL_284ed0fb376b471591e20400610348a6","value":"Map:   0%"}},"cf2b268b067e4faf8f1a0b843c1658df":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_8bfef4076a5848e286a56a3a4c6befaf","max":13,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fd2d73720c1249d38e473e02a89aa506","value":13}},"f54b81c0c07d41b0a5d5382770c57ac3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8712b85e4dce48639b9be816ec9883a1","placeholder":"​","style":"IPY_MODEL_090908704adb4e4189b9834d932f0abe","value":" 0/13 [00:00&lt;?, ? examples/s]"}},"1a7459d4d27b4acb871e25c7268f2e93":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"e7c39f43f441428cba8623dbe50fc35a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"284ed0fb376b471591e20400610348a6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8bfef4076a5848e286a56a3a4c6befaf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd2d73720c1249d38e473e02a89aa506":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8712b85e4dce48639b9be816ec9883a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"090908704adb4e4189b9834d932f0abe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}